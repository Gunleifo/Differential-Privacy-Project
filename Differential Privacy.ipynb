{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing Privacy and Accuracy in Machine Learning Models with Differential Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction & Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project explores how **Differential Privacy Stochastic Gradient Descent (DP-SGD)** and **Model Agnostic Private Learning (MAPL)** impact machine learning models. Specifically, we examine whether DP techniques interfere with model accuracy and the evolution of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup - Install Required Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below if there are missing packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install pandas numpy\n",
    "%pip install scikit-learn\n",
    "%pip install ucimlrepo\n",
    "%pip install imblearn\n",
    "%pip install tabulate\n",
    "%pip install boruta\n",
    "%pip install torch\n",
    "%pip install opacus\n",
    "print(\"Libraries installed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Exploration & Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are importing the relevant libraries and getting the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ucimlrepo import fetch_ucirepo #to retrieve the dataset\n",
    "\n",
    "# Getting the data\n",
    "dataset_id = 891  # our chosen dataset\n",
    "dataset = fetch_ucirepo(id=dataset_id)\n",
    "df = dataset.data.original\n",
    "\n",
    "# # Previous way to retrieve the dataset (for documentation)\n",
    "# url = 'https://archive.ics.uci.edu/static/public/891/data.csv'\n",
    "# df = pd.read_csv(url)\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have observed that the dataset contains 253,680 records with 23 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking basic Dataset Information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have observed that all features are stored as integer data types:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows the features and their descriptions:\n",
    "\n",
    "| Variable Name     | Role    | Type    | Description                                                                 |\n",
    "|-------------------|---------|---------|-----------------------------------------------------------------------------|\n",
    "| ID                | ID      | Integer | Patient ID                                                                  |\n",
    "| Diabetes_binary   | Target  | Binary  | 0 = no diabetes 1 = prediabetes or diabetes                                 |\n",
    "| HighBP            | Feature | Binary  | 0 = no high BP 1 = high BP                                                  |\n",
    "| HighChol          | Feature | Binary  | 0 = no high cholesterol 1 = high cholesterol                                |\n",
    "| CholCheck         | Feature | Binary  | 0 = no cholesterol check in 5 years 1 = yes cholesterol check in 5 years    |\n",
    "| BMI               | Feature | Integer | Body Mass Index                                                             |\n",
    "| Smoker            | Feature | Binary  | Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes] 0 = no 1 = yes |\n",
    "| Stroke            | Feature | Binary  | (Ever told) you had a stroke. 0 = no 1 = yes                                |\n",
    "| HeartDiseaseorAttack | Feature | Binary | coronary heart disease (CHD) or myocardial infarction (MI) 0 = no 1 = yes  |\n",
    "| PhysActivity      | Feature | Binary  | physical activity in past 30 days - not including job 0 = no 1 = yes        |\n",
    "| Fruits            | Feature | Binary  | Consume Fruit 1 or more times per day 0 = no 1 = yes                        |\n",
    "| Veggies           | Feature | Binary  | Consume Vegetables 1 or more times per day 0 = no 1 = yes                   |\n",
    "| HvyAlcoholConsump | Feature | Binary  | Heavy drinkers (adult men having more than 14 drinks per week and adult women having more than 7 drinks per week) 0 = no 1 = yes |\n",
    "| AnyHealthcare     | Feature | Binary  | Have any kind of health care coverage, including health insurance, prepaid plans such as HMO, etc. 0 = no 1 = yes |\n",
    "| NoDocbcCost       | Feature | Binary  | Was there a time in the past 12 months when you needed to see a doctor but could not because of cost? 0 = no 1 = yes |\n",
    "| GenHlth           | Feature | Integer | General health: 1 = excellent 2 = very good 3 = good 4 = fair 5 = poor |\n",
    "| MentHlth          | Feature | Integer | For how many days during the past 30 days was your mental health not good? scale 1-30 days |\n",
    "| PhysHlth          | Feature | Integer | For how many days during the past 30 days was your physical health not good? scale 1-30 days |\n",
    "| DiffWalk          | Feature | Binary  | Do you have serious difficulty walking or climbing stairs? 0 = no 1 = yes   |\n",
    "| Sex               | Feature | Binary  | 0 = female 1 = male                                                    |\n",
    "| Age               | Feature | Integer | 13 levels, 1 = 18-24, 9 = 60-64, 13 = 80 or older              |\n",
    "| Education         | Feature | Integer | 6 levels, 1 = Never attended school or only kindergarten, 2 = Grades 1 through 8, 3 = Grades 9 through 11, 4 = Grade 12 or GED, 5 = College 1 year to 3 years, 6 = College 4 years or more |\n",
    "| Income            | Feature | Integer | 8 levels, 1 = less than $10,000, 5 = less than $35,000, 8 = $75,000 or more |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data types\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have observed basic statistics for the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have observed that there are no missing values (as stated in the dataset description):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have observed that the dataset only has 13.93% records with diabetes. We will address this imbalance later during data cleaning and preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking distribution of dataset\n",
    "diabetes_counts = df['Diabetes_binary'].value_counts()\n",
    "print(\"Distribution of target variable:\")\n",
    "print(diabetes_counts)\n",
    "print(f\"Percentage of records with diabetes: {diabetes_counts[1]/len(df)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have observed a basic relationship between the features using a correlation matrix. We still need to explain what we can see from this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually in preprocessing we would handle missing values, encoding binary data (True -> 1), encoding categorical data, feature scaling. However, since the dataset is already clean and preprocessed, we will only address the class imbalance issue.\n",
    "In the balanced datased, we have reduced the number of records with diabetes to match the number of records without diabetes, so that the dataset is balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Class Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_with_diabetes = df['Diabetes_binary'].value_counts()[1]\n",
    "\n",
    "print(\"\\nOriginal Dataset:\")\n",
    "print(f\"- Total samples in the original dataset: {len(df)}\")\n",
    "print(f\"- Samples with diabetes (class 1): {num_with_diabetes}\")\n",
    "print(f\"- Samples without diabetes (class 0): {df['Diabetes_binary'].value_counts()[0]}\")\n",
    "\n",
    "df_no_diabetes = df[df['Diabetes_binary'] == 0].sample(n=num_with_diabetes, random_state=42)\n",
    "df_with_diabetes = df[df['Diabetes_binary'] == 1]\n",
    "\n",
    "df_balanced = pd.concat([df_no_diabetes, df_with_diabetes])\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_balanced_noTarget = df_balanced.drop(columns=[\"Diabetes_binary\", \"ID\"])\n",
    "y_balanced = df_balanced[\"Diabetes_binary\"]\n",
    "\n",
    "print(\"\\nBalanced Dataset:\")\n",
    "print(f\"- Total samples in the balanced dataset: {len(df_balanced)}\")\n",
    "print(df_balanced['Diabetes_binary'].value_counts())\n",
    "\n",
    "print(f\"- Samples without diabetes (class 0): {df_balanced['Diabetes_binary'].value_counts()[0]}\")\n",
    "print(f\"- Samples with diabetes (class 1): {df_balanced['Diabetes_binary'].value_counts()[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Data Splitting Strategy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training our models we have to split the data into a training set and a test set. We have chosen a 80/20 split, which ensures we have enough training data for the model to learn patterns and enough data for performance evaluation. We have used stratified sampling to ensure that both the training set and test set includes a 50/50 split of records having diabetes or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_balanced = df_balanced.drop('Diabetes_binary', axis=1) # drop the target column\n",
    "y_balanced = df_balanced['Diabetes_binary']\n",
    "\n",
    "X_imbalanced = df.drop('Diabetes_binary', axis=1) #drop the target column\n",
    "y_imbalanced = df['Diabetes_binary']\n",
    "\n",
    "# split into train (70%) and temp (30%)\n",
    "X_train_bal, X_temp_bal, y_train_bal, y_temp_bal = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.3, random_state=42, stratify=y_balanced\n",
    ")\n",
    "\n",
    "# split temp set into validation (10%) and test (20%)\n",
    "X_val_bal, X_test_bal, y_val_bal, y_test_bal = train_test_split(\n",
    "    X_temp_bal, y_temp_bal, test_size=2/3, random_state=42, stratify=y_temp_bal\n",
    ")\n",
    "\n",
    "# Imbalanced dataset\n",
    "X_train_imb, X_temp_imb, y_train_imb, y_temp_imb = train_test_split(\n",
    "    X_imbalanced, y_imbalanced, test_size=0.3, random_state=42, stratify=y_imbalanced\n",
    ")\n",
    "\n",
    "X_val_imb, X_test_imb, y_val_imb, y_test_imb = train_test_split(\n",
    "    X_temp_imb, y_temp_imb, test_size=2/3, random_state=42, stratify=y_temp_imb\n",
    ")\n",
    "\n",
    "print(f\"Balanced Training set: {X_train_bal.shape[0]} samples\")\n",
    "print(f\"Balanced Validation set: {X_val_bal.shape[0]} samples\")\n",
    "print(f\"Balanced Testing set: {X_test_bal.shape[0]} samples\")\n",
    "\n",
    "print(\"\\nClass distribution in balanced training set:\")\n",
    "print(y_train_bal.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nClass distribution in balanced validation set:\")\n",
    "print(y_val_bal.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nClass distribution in balanced testing set:\")\n",
    "print(y_test_bal.value_counts(normalize=True))\n",
    "\n",
    "print(f\"\\nImbalanced Training set: {X_train_imb.shape[0]} samples\")\n",
    "print(f\"Imbalanced Validation set: {X_val_imb.shape[0]} samples\")\n",
    "print(f\"Imbalanced Testing set: {X_test_imb.shape[0]} samples\")\n",
    "\n",
    "print(\"\\nClass distribution in imbalanced training set:\")\n",
    "print(y_train_imb.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nClass distribution in imbalanced validation set:\")\n",
    "print(y_val_imb.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nClass distribution in imbalanced testing set:\")\n",
    "print(y_test_imb.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might be a defense against the attacks, because the less features we have, the less information we leak.\n",
    "\n",
    "We need to explain which features we have chosen based on the data exploration above and the following feature selection methods. We can use variance threshold, correlation matrix, kbest, rfe, boruta...\n",
    "\n",
    "['HighBP', 'HighChol', 'BMI', 'GenHlth', 'Age'] ok with V.T. and C.M.\n",
    "\n",
    "Might want to use more features to try the attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import (\n",
    "    RFE,\n",
    "    SelectKBest,\n",
    "    VarianceThreshold,\n",
    "    mutual_info_classif,\n",
    ")\n",
    "from boruta import BorutaPy\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "def save_results(results, file_path, columns):\n",
    "    results_df = pd.DataFrame(results, columns=columns)\n",
    "    if not os.path.exists(os.path.dirname(file_path)):\n",
    "        os.makedirs(os.path.dirname(file_path))\n",
    "    results_df.to_csv(file_path, index=False)\n",
    "\n",
    "def calculate_metrics(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    return (accuracy, precision, recall, f1)\n",
    "\n",
    "def getVariances(threshold, data):\n",
    "    var_threshold = VarianceThreshold(threshold=threshold)\n",
    "    var_threshold.fit(data)\n",
    "    variances = var_threshold.variances_\n",
    "    # Create a DataFrame for variances\n",
    "    variances_df = pd.DataFrame(variances, index=data.columns, columns=[\"Variance\"])\n",
    "    # Sort variances in descending order\n",
    "    variances_df = variances_df.sort_values(by=\"Variance\", ascending=False)\n",
    "    # Features with variance >= threshold\n",
    "    features_high_variance = variances_df[variances_df[\"Variance\"] >= threshold]\n",
    "    # Features with variance < threshold\n",
    "    features_low_variance = variances_df[variances_df[\"Variance\"] < threshold]\n",
    "    return variances_df, features_high_variance, features_low_variance\n",
    "\n",
    "def getKBest(k, data, target):\n",
    "    # selection\n",
    "    selector = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "    x_kbest = selector.fit_transform(data, target)\n",
    "    # Create a DataFrame with the selected features\n",
    "    kbest_features = data.columns[selector.get_support()]\n",
    "    x_kbest_df = pd.DataFrame(x_kbest, columns=kbest_features)\n",
    "    return x_kbest_df\n",
    "\n",
    "def process_kbest(data, target, k, file_path):\n",
    "    try:\n",
    "        x_kbest_df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        x_kbest_df = getKBest(k, data, target)\n",
    "        x_kbest_df[target.name] = target.values\n",
    "        x_kbest_df.to_csv(file_path, index=False)\n",
    "    x_kbest_df = x_kbest_df.drop(columns=[target.name], axis=1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x_kbest_df, target, test_size=0.3, random_state=42, stratify=target\n",
    "    )\n",
    "    rf_model.fit(x_train, y_train)\n",
    "    y_pred = rf_model.predict(x_test)\n",
    "    accuracy, precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
    "    kbest_features_names = x_kbest_df.columns.tolist()\n",
    "    return (k, accuracy, precision, recall, f1, kbest_features_names)\n",
    "\n",
    "def getRFE(k, data, target):\n",
    "    # selection\n",
    "    selector = RFE(estimator=rf_model, n_features_to_select=k)\n",
    "    x_rfe = selector.fit_transform(data, target)\n",
    "    # Create a DataFrame with the selected features\n",
    "    rfe_features = data.columns[selector.get_support()]\n",
    "    x_rfe_df = pd.DataFrame(x_rfe, columns=rfe_features)\n",
    "    return x_rfe_df\n",
    "\n",
    "def process_rfe(data, target, k, file_path):\n",
    "    try:\n",
    "        x_rfe_df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        x_rfe_df = getRFE(k, data, target)\n",
    "        x_rfe_df[target.name] = target.values\n",
    "        x_rfe_df.to_csv(file_path, index=False)\n",
    "    x_rfe_df = x_rfe_df.drop(columns=[target.name], axis=1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x_rfe_df, target, test_size=0.3, random_state=42, stratify=target\n",
    "    )\n",
    "    rf_model.fit(x_train, y_train)\n",
    "    y_pred = rf_model.predict(x_test)\n",
    "    accuracy, precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
    "    rfe_features_names = x_rfe_df.columns.tolist()\n",
    "    return (k, accuracy, precision, recall, f1, rfe_features_names)\n",
    "\n",
    "def apply_boruta(data, target):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        data, target, test_size=0.3, random_state=42, stratify=target\n",
    "    )\n",
    "    boruta = BorutaPy(\n",
    "        rf_model,\n",
    "        n_estimators=\"auto\",\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "    )\n",
    "    boruta.fit(x_train.values, y_train.values)\n",
    "    sel_x_train = boruta.transform(x_train.values)\n",
    "    sel_x_test = boruta.transform(x_test.values)\n",
    "    rf_model.fit(sel_x_train, y_train)\n",
    "    y_pred = rf_model.predict(sel_x_test)\n",
    "    accuracy, precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
    "    selected_features = x_train.columns[boruta.support_].tolist()\n",
    "    return (accuracy, precision, recall, f1, selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances_df, features_high_variance, features_low_variance = getVariances(\n",
    "    0, df_balanced_noTarget\n",
    ")\n",
    "\n",
    "# Plot variances of all features\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(variances_df.index, variances_df['Variance'], color='skyblue')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Variance')\n",
    "plt.title('Feature Variances')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Highlight features with high and low variance\n",
    "print(\"\\nFeatures with High Variance:\")\n",
    "print(features_high_variance)\n",
    "print(\"\\nFeatures with Low Variance:\")\n",
    "print(features_low_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = df_balanced.corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Focus on correlations with the target variable\n",
    "diabetes_correlations = correlation_matrix['Diabetes_binary'].sort_values(ascending=False)\n",
    "print(\"\\nFeatures correlated with Diabetes (sorted):\")\n",
    "print(diabetes_correlations)\n",
    "\n",
    "# Visualize correlations with the target\n",
    "plt.figure(figsize=(12, 8))\n",
    "diabetes_correlations[1:].plot(kind='bar')  # Exclude self-correlation\n",
    "plt.title(\"Feature Correlation with Diabetes\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Correlation Coefficient\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3 KBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# columns = [\"Model\", \"K\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Features\"]\n",
    "# for k in range(1, df_balanced_noTarget.shape[1] + 1):\n",
    "#     file_path = f\"featureSelectionData/kbest/k/{k}best_features.csv\"\n",
    "#     kbestResult = process_kbest(df_balanced_noTarget, y_balanced, k, file_path)\n",
    "#     results.append((\"rf\",) + kbestResult)\n",
    "# save_results(\n",
    "#     results, f\"featureSelectionData/kbest/kbest_rf_results.csv\", columns\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.4 RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# columns = [\"Model\", \"K\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Features\"]\n",
    "# for k in range(1, df_balanced_noTarget.shape[1] + 1):\n",
    "#     file_path = f\"featureSelectionData/rfe/k/{k}rfe_features.csv\"\n",
    "#     rfeResult = process_rfe(df_balanced_noTarget, y_balanced, k, file_path)\n",
    "#     results.append((\"rf\",) + rfeResult)\n",
    "# save_results(results, f\"featureSelectionData/rfe/rfe_rf_results.csv\", columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.5 Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Features\"]\n",
    "# accuracy, precision, recall, f1, selected_features = apply_boruta(\n",
    "#     df_balanced_noTarget, y_balanced\n",
    "# )\n",
    "# save_results(\n",
    "#     [(\"rf\", accuracy, precision, recall, f1, selected_features)],\n",
    "#     f\"featureSelectionData/boruta/boruta_rf_results.csv\",\n",
    "#     columns,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Tuning model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# params = {\n",
    "#     'max_depth': [2,3,5,10,20],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [5,10,20,50,100,200],\n",
    "#     'n_estimators': [50,100,150,200]\n",
    "# }\n",
    "\n",
    "# # Instantiate the grid search model\n",
    "# grid_search = GridSearchCV(estimator=rf_model,\n",
    "#                            param_grid=params,\n",
    "#                            cv = 4,\n",
    "#                            n_jobs=-1, verbose=1, scoring=\"precision\")\n",
    "\n",
    "# important_features = ['HighBP', 'HighChol', 'BMI', 'GenHlth', 'Age', 'Income']\n",
    "# X_train_important = X_train_bal[important_features]\n",
    "\n",
    "# grid_search.fit(X_train_important, y_train_bal)\n",
    "# print(\"\\nBest parameters found: \", grid_search.best_estimator_)\n",
    "# rf_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(max_depth=2, min_samples_leaf=5, n_jobs=-1,\n",
    "                       random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Machine Learning Model without Differential Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are importing the relevant libraries to train our models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Using all features (balanced dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test_bal)\n",
    "\n",
    "# Checking accuracy and classification report\n",
    "print(\"Accuracy:\", accuracy_score(y_test_bal, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_bal, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Using selected features (balanced dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Define important features\n",
    "important_features = ['HighBP', 'HighChol', 'BMI', 'GenHlth', 'Age', 'Income']\n",
    "\n",
    "# Filter X_train_bal and X_test_bal to include only important features\n",
    "X_train_important = X_train_bal[important_features]\n",
    "X_test_important = X_test_bal[important_features]\n",
    "# Train with the balanced filtered dataset\n",
    "rf_model.fit(X_train_important, y_train_bal)\n",
    "\n",
    "# Save the model\n",
    "with open('models/rf_selectedF_balanced_model.pkl', 'wb') as file:\n",
    "    pickle.dump(rf_model, file)\n",
    "\n",
    "# Make predictions using the filtered test set\n",
    "y_pred = rf_model.predict(X_test_important)\n",
    "\n",
    "# Checking accuracy and classification report\n",
    "print(\"Accuracy:\", accuracy_score(y_test_bal, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_bal, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precision: How many predicted positives are actually positive?\n",
    "- Recall: How many actual positives were correctly identified?\n",
    "- F1-score: A balance between precision and recall.\n",
    "- Support: Number of actual occurrences of each class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Using selected features (imbalanced dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the imbalanced training and test sets to include only important features\n",
    "X_train_imb_important = X_train_imb[important_features]\n",
    "X_test_imb_important = X_test_imb[important_features]\n",
    "\n",
    "# Train with the imbalanced filtered dataset\n",
    "rf_model.fit(X_train_imb_important, y_train_imb)\n",
    "\n",
    "# Make predictions using the filtered test set\n",
    "y_pred = rf_model.predict(X_test_imb_important)\n",
    "\n",
    "# Checking accuracy and classification report\n",
    "print(\"Accuracy:\", accuracy_score(y_test_imb, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test_imb, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model over prioritizes the majority class (0 - no diabetes), as it was trained with the imbalanced data.**\n",
    "\n",
    "Comparison:\n",
    "\n",
    "Balanced data (6.2) - Lower accuracy (74%) but much better at detecting class 1 - diabetes (79%), as it gives the same importance to both classes.\n",
    "\n",
    "Imbalanced data (6.3) - Higher accuracy (86%) but poor detection of class 1 - diabetes (16%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.1 Using validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter balanced training and test sets to include only important features\n",
    "X_train_bal_important = X_train_bal[important_features]\n",
    "X_test_bal_important = X_test_bal[important_features]\n",
    "X_val_bal_important = X_val_bal[important_features]\n",
    "\n",
    "# Train with the filtered balanced dataset\n",
    "rf_model.fit(X_train_bal_important, y_train_bal)\n",
    "\n",
    "# Make predictions using the filtered test set\n",
    "y_pred_bal = rf_model.predict(X_test_bal_important)\n",
    "\n",
    "# Checking accuracy and classification report for balanced test set\n",
    "print(\"Balanced Accuracy:\", accuracy_score(y_test_bal, y_pred_bal))\n",
    "print(\"\\nBalanced Classification Report:\")\n",
    "print(classification_report(y_test_bal, y_pred_bal))\n",
    "\n",
    "# Evaluate validation set - for documentation\n",
    "y_pred_val_bal = rf_model.predict(X_val_bal_important)\n",
    "print(\"\\nBalanced Validation Accuracy:\", accuracy_score(y_val_bal, y_pred_val_bal))\n",
    "print(\"\\nBalanced Validation Classification Report:\")\n",
    "print(classification_report(y_val_bal, y_pred_val_bal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.2 Using SMOTE balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "X = df[important_features]\n",
    "y = df['Diabetes_binary']\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "# SMOTE balances the dataset by generating synthetic samples for the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "print(\"Before SMOTE:\", Counter(y))  # Shows original class distribution\n",
    "print(\"After SMOTE:\", Counter(y_resampled))  # Shows balanced class distribution\n",
    "\n",
    "print(\"Original dataset shape:\", X.shape, y.shape)\n",
    "print(\"Resampled dataset shape:\", X_resampled.shape, y_resampled.shape)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=2/3, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Train with the balanced dataset split\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Checking accuracy and classification report\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import copy\n",
    "\n",
    "# Import model\n",
    "with open('models/rf_selectedF_balanced_model.pkl', 'rb') as file:\n",
    "    # Use rf_model as model. \n",
    "    # Copy rf_model_fs_bal in rf_model every time you have to do \n",
    "    # a task that needs the original loaded model (example in MIA)\n",
    "    rf_model = pickle.load(file)\n",
    "rf_model_fs_bal = copy.deepcopy(rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.1 - Model Inversion Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np    \n",
    "\n",
    "def model_inversion_attack(model, target_class, feature_names, X_train, iterations=300):\n",
    "\n",
    "    # Get min/max values for each feature - only for the specified important features\n",
    "    min_values = X_train[feature_names].min()\n",
    "    max_values = X_train[feature_names].max()\n",
    "    \n",
    "    # Start with random values for the important features\n",
    "    sample = {}\n",
    "    for feature in feature_names:\n",
    "        sample[feature] = np.random.uniform(min_values[feature], max_values[feature])\n",
    "    \n",
    "    # Save best sample and confidence\n",
    "    best_sample = sample.copy()\n",
    "    best_confidence = 0\n",
    "    \n",
    "    # Optimize sample through iterations\n",
    "    step_size = 0.05\n",
    "    for i in range(iterations):\n",
    "        # Calculate current confidence\n",
    "        current_df = pd.DataFrame([sample])\n",
    "        confidence = model.predict_proba(current_df)[0][target_class]\n",
    "        \n",
    "        # Save if better than previous\n",
    "        if confidence > best_confidence:\n",
    "            best_confidence = confidence\n",
    "            best_sample = sample.copy()\n",
    "        \n",
    "        # Optimize one feature at a time, but only the important features\n",
    "        for feature in feature_names:\n",
    "            original = sample[feature]\n",
    "            \n",
    "            # Try positive change\n",
    "            sample[feature] = min(max_values[feature], original + step_size)\n",
    "            plus_conf = model.predict_proba(pd.DataFrame([sample]))[0][target_class]\n",
    "            \n",
    "            # Try negative change\n",
    "            sample[feature] = max(min_values[feature], original - step_size)\n",
    "            minus_conf = model.predict_proba(pd.DataFrame([sample]))[0][target_class]\n",
    "            \n",
    "            # Choose the best direction\n",
    "            if plus_conf > minus_conf and plus_conf > confidence:\n",
    "                sample[feature] = min(max_values[feature], original + step_size)\n",
    "            elif minus_conf > plus_conf and minus_conf > confidence:\n",
    "                sample[feature] = max(min_values[feature], original - step_size)\n",
    "            else:\n",
    "                sample[feature] = original\n",
    "        \n",
    "        # Reduce step size over time\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            step_size *= 0.9\n",
    "    \n",
    "    # Find most similar training example\n",
    "    reconstructed_df = pd.DataFrame([best_sample])\n",
    "    \n",
    "    # Calculate distance to each training example, but use only the important features\n",
    "    distances = []\n",
    "    for _, row in X_train.iterrows():\n",
    "        dist = 0\n",
    "        for feature in feature_names:  # Calculate distance based only on important features\n",
    "            dist += (row[feature] - best_sample[feature])**2\n",
    "        distances.append(np.sqrt(dist))\n",
    "    \n",
    "    most_similar_idx = np.argmin(distances)\n",
    "    most_similar = X_train.iloc[[most_similar_idx]]\n",
    "    \n",
    "    return {\n",
    "        'reconstructed': reconstructed_df,\n",
    "        'most_similar': most_similar,\n",
    "        'confidence': best_confidence,\n",
    "        'similarity': 1.0 / (1.0 + np.min(distances))  # Convert distance to similarity (0-1)\n",
    "    }\n",
    "\n",
    "def analyze_model_inversion_attack(model, X_train, feature_names, target_class=1):\n",
    "    \n",
    "    print(\"Running Model Inversion Attack...\")\n",
    "    results = model_inversion_attack(model, target_class, feature_names, X_train)\n",
    "    \n",
    "    print(f\"Attack completed with confidence: {results['confidence']:.4f}\")\n",
    "    print(f\"Similarity to closest training sample: {results['similarity']:.4f}\")\n",
    "    \n",
    "    # Visualize comparison between reconstructed and original sample\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Get data for visualization\n",
    "    recon = results['reconstructed']\n",
    "    orig = results['most_similar']\n",
    "    \n",
    "    # Plot features (use all important features or limit to top 8)\n",
    "    display_features = feature_names[:8] if len(feature_names) > 8 else feature_names\n",
    "    \n",
    "    x = np.arange(len(display_features))\n",
    "    width = 0.3\n",
    "    \n",
    "    plt.bar(x - width/2, [recon[f].values[0] for f in display_features], width, label='Reconstructed')\n",
    "    plt.bar(x + width/2, [orig[f].values[0] for f in display_features], width, label='Original')\n",
    "    \n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Model Inversion Attack: Reconstructed vs. Original Sample')\n",
    "    plt.xticks(x, display_features, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Compare all features in detail\n",
    "    print(\"\\n============= FEATURE-SPECIFIC ANALYSIS =============\")\n",
    "    for feature in feature_names:\n",
    "        recon_value = recon[feature].values[0]\n",
    "        orig_value = orig[feature].values[0]\n",
    "        \n",
    "        diff = abs(recon_value - orig_value)\n",
    "        \n",
    "        print(f\"Feature: {feature}\")\n",
    "        print(f\"  Original value: {orig_value:.2f}\")\n",
    "        print(f\"  Reconstructed value: {recon_value:.2f}\")\n",
    "        print(f\"  Absolute difference: {diff:.2f}\")\n",
    "        print()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are defining the important features that we have previously used\n",
    "important_features = ['GenHlth', 'HighBP', 'DiffWalk', 'BMI', 'HighChol', 'Age', \n",
    "                      'HeartDiseaseorAttack', 'PhysHlth', 'Stroke', 'MentHlth', \n",
    "                      'CholCheck', 'Smoker', 'NoDocbcCost', 'Sex', 'AnyHealthcare', \n",
    "                      'Income', 'Education']\n",
    "\n",
    "# We filter the training data to only contain important features\n",
    "X_train_important = X_train_bal[important_features]\n",
    "\n",
    "# We run the Model Inversion Attack on the non private model\n",
    "print(\"\\n============= MODEL INVERSION ATTACK =============\")\n",
    "results = analyze_model_inversion_attack(\n",
    "    model=rf_model,                   # Standard model from section 6\n",
    "    X_train=X_train_important,        # Important features from training data\n",
    "    feature_names=important_features, # Names of important features\n",
    "    target_class=1                    # Attack diabetes class (1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.2 Membership Inference Attack(MIA) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---1. Standard MIA---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this attack is to determine whether a given sample was used in training. \n",
    "\n",
    "It queries the model with different data points and analyzes the confidence scores. This happens because the model behaves differently for data it has seen before and new data. As this one was trained without DP, it is easier to leak private data as it may have \"memorized\" training data. A classification model would classify a training data record to its true class with a high confidence score while classifying a test data record to its true class with a relatively small confidence. These different behaviors of ML models enable an attacker of MIAs to build attack models to distinguish members from non-members of the training dataset.\n",
    "\n",
    "The more overfitted a machine learning model is, the easier it will be for an adversary to stage membership inference attacks against it. Therefore, a machine model that generalizes well on unseen examples is also more secure against membership inference.\n",
    "\n",
    "Membership inference attacks are not successful on all kinds of machine learning tasks. To create an efficient attack model, the adversary must be able to explore the feature space. (HigRes. photos: Hard, tabular data: Easy)\n",
    "\n",
    "** TODO: try with DP model(s) as well **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original model\n",
    "rf_model = copy.deepcopy(rf_model_fs_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter #?\n",
    "\n",
    "assert 'rf_model' in locals(), \"Random Forest model (rf_model) is not defined!\" #if not defined, run 4.2\n",
    "\n",
    "# Get confidence scores (highest probability prediction) for train and test samples\n",
    "train_confidences = rf_model.predict_proba(X_train).max(axis=1)\n",
    "test_confidences = rf_model.predict_proba(X_test).max(axis=1)\n",
    "\n",
    "# Set attack threshold (mean confidence of training data)\n",
    "threshold = np.mean(train_confidences)\n",
    "\n",
    "# Attack: Predict \"1\" (member) if confidence > threshold, else \"0\" (non-member)\n",
    "train_preds = [1 if c > threshold else 0 for c in train_confidences]\n",
    "test_preds = [0 if c <= threshold else 1 for c in test_confidences]\n",
    "\n",
    "# True labels: training samples = 1 (member), test samples = 0 (non-member)\n",
    "y_true = [1] * len(train_preds) + [0] * len(test_preds)\n",
    "y_pred = train_preds + test_preds\n",
    "\n",
    "attack_accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "train_mean_conf = np.mean(train_confidences)\n",
    "test_mean_conf = np.mean(test_confidences)\n",
    "\n",
    "print(f\" Accuracy: {attack_accuracy:.2f}\")\n",
    "print(f\" Avg Train Confidence: {train_mean_conf:.2f}\")\n",
    "print(f\" Avg Test Confidence: {test_mean_conf:.2f}\")\n",
    "print(f\" Attack Threshold Used: {threshold:.2f}\\n\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(train_confidences, bins=50, alpha=0.6, label=\"Train (Member)\", color='blue')\n",
    "plt.hist(test_confidences, bins=50, alpha=0.6, label=\"Test (Non-Member)\", color='red')\n",
    "plt.axvline(threshold, color='black', linestyle='dashed', label=\"Attack Threshold\")\n",
    "plt.xlabel(\"Model Confidence Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Membership Inference Attack - Confidence Score Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 62% of accuracy means that the model partially leaks private information. It is possible to distinguish between training and testing samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- 2. Real World Case MIA ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# # To keep: For development\n",
    "# real_members = X_train.head(5)\n",
    "# print(\"First 5 Real Members (Training Set):\\n\", real_members)\n",
    "\n",
    "risky_patients = [\n",
    "    # If adding more patients, make sure that the attributes have valid values according to the dataset\n",
    "\n",
    "    {\n",
    "        'GenHlth': 3, 'HighBP': 1, 'DiffWalk': 0, 'BMI': 21, 'HighChol': 0, 'Age': 12, \n",
    "        'HeartDiseaseorAttack': 0, 'PhysHlth': 0, 'Stroke': 0, 'MentHlth': 0, 'CholCheck': 1, \n",
    "        'Smoker': 0, 'Veggies': 1, 'HvyAlcoholConsump': 0, 'PhysActivity': 1, 'Education': 4, \n",
    "        'Income': 4\n",
    "    },  # Patient used in the test_set. ID nr 178592\n",
    "\n",
    "    {\n",
    "        'GenHlth': 2, 'HighBP': 1, 'DiffWalk': 0, 'BMI': 39, 'HighChol': 1, 'Age': 7, \n",
    "        'HeartDiseaseorAttack': 0, 'PhysHlth': 0, 'Stroke': 0, 'MentHlth': 0, 'CholCheck': 1, \n",
    "        'Smoker': 0, 'Veggies': 1, 'HvyAlcoholConsump': 0, 'PhysActivity': 1, 'Education': 4, \n",
    "        'Income': 1\n",
    "    },  # Patient used in the test_set. ID nr 318886\n",
    "\n",
    "    {\n",
    "        'GenHlth': 4, 'HighBP': 0, 'DiffWalk': 1, 'BMI': 23, 'HighChol': 0, 'Age': 8, \n",
    "        'HeartDiseaseorAttack': 1, 'PhysHlth': 24, 'Stroke': 0, 'MentHlth': 22, 'CholCheck': 0, \n",
    "        'Smoker': 1, 'Veggies': 0, 'HvyAlcoholConsump': 1, 'PhysActivity': 0, 'Education': 2, \n",
    "        'Income': 1\n",
    "    },  # Random person created for testing purposes\n",
    "\n",
    "    {\n",
    "        'GenHlth': 5, 'HighBP': 1, 'DiffWalk': 1, 'BMI': 40, 'HighChol': 1, 'Age': 9, \n",
    "        'HeartDiseaseorAttack': 0, 'PhysHlth': 15, 'Stroke': 0, 'MentHlth': 18, 'CholCheck': 1, \n",
    "        'Smoker': 1, 'Veggies': 1, 'HvyAlcoholConsump': 0, 'PhysActivity': 0, 'Education': 4, \n",
    "        'Income': 3\n",
    "    }   # Patient ID 0. Taken from the dataset. Probably not used in test_set? - ToDo\n",
    "]\n",
    "\n",
    "# Convert risky patients to pandas dataFrame as it is the expected input format by the RF model\n",
    "risky_df = pd.DataFrame(risky_patients)\n",
    "\n",
    "risky_df = risky_df[X_train.columns]\n",
    "\n",
    "# Predict confidence scores for risky patients\n",
    "risky_confidences = rf_model.predict_proba(risky_df).max(axis=1)\n",
    "\n",
    "# Determine membership status using the same attack threshold from the standard MIAttack\n",
    "risky_membership = ['Member' if c > threshold else 'Non-Member' for c in risky_confidences]\n",
    "\n",
    "for i, (conf, membership) in enumerate(zip(risky_confidences, risky_membership)):\n",
    "    print(f\"Risky Patient {i + 1}: Confidence = {conf:.2f}, Predicted Membership = {membership}\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(train_confidences, bins=50, alpha=0.6, color='blue', label=\"Train (Member)\")\n",
    "plt.hist(test_confidences, bins=50, alpha=0.6, color='red', label=\"Test (Non-Member)\")\n",
    "\n",
    "for i, conf in enumerate(risky_confidences):\n",
    "    plt.axvline(conf, color='green', linestyle='dashed', label=f\"Risky Patient {i + 1}: {conf:.2f}\")\n",
    "\n",
    "plt.axvline(threshold, color='black', linestyle='solid', label=f\"Attack Threshold: {threshold:.2f}\")\n",
    "plt.xlabel(\"Model Confidence Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Membership Inference Attack - Risky Patients\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add description, explain results and describe and how it can relate to a real world case (like an insurance company)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.3 Attribute Inference Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original model\n",
    "rf_model = copy.deepcopy(rf_model_fs_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "assert 'rf_model' in locals(), \"Random Forest model (rf_model) is not defined!\" #if not defined, run 6.6\n",
    "\n",
    "sensitive_feature = 'Income'\n",
    "\n",
    "# Exclude 'Income' from training features - because we will be trying to infer this attribute\n",
    "attack_features = [f for f in X_train.columns if f != sensitive_feature]\n",
    "\n",
    "# Get confidence scores from the target model\n",
    "# For each prediction, predict_proba() gives an array of probabilities for each class (8 in case of Income)\n",
    "train_confidences = rf_model.predict_proba(X_train).max(axis=1)\n",
    "test_confidences = rf_model.predict_proba(X_test).max(axis=1)\n",
    "\n",
    "# Add confidence scores to the dataset\n",
    "X_train_attack = X_train[attack_features].copy()\n",
    "X_train_attack['model_confidence'] = train_confidences\n",
    "\n",
    "X_test_attack = X_test[attack_features].copy()\n",
    "X_test_attack['model_confidence'] = test_confidences\n",
    "\n",
    "\n",
    "y_train_attack = X_train[sensitive_feature]\n",
    "y_test_attack = X_test[sensitive_feature]\n",
    "\n",
    "# Train the Inference Model (using random forest)\n",
    "rf_model.fit(X_train_attack, y_train_attack)\n",
    "\n",
    "# Evaluate the Inference Model\n",
    "y_pred_attack = rf_model.predict(X_test_attack)\n",
    "\n",
    "attack_accuracy = accuracy_score(y_test_attack, y_pred_attack)\n",
    "\n",
    "train_mean_conf = np.mean(train_confidences)\n",
    "test_mean_conf = np.mean(test_confidences)\n",
    "\n",
    "print(\"\\nAttribute Inference Attack on 'Income':\")\n",
    "print(f\"Attack Accuracy: {attack_accuracy:.2f}\")\n",
    "print(f\"Avg Train Confidence: {train_mean_conf:.2f}\")\n",
    "print(f\"Avg Test Confidence: {test_mean_conf:.2f}\\n\")\n",
    "\n",
    "report = classification_report(y_test_attack, y_pred_attack, output_dict=True)\n",
    "\n",
    "def print_classification_report(report):\n",
    "    headers = [\"Metric\"] + [str(label) for label in report if label not in ('accuracy', 'macro avg', 'weighted avg')]\n",
    "    rows = [\n",
    "        [\"Precision\"] + [report[label]['precision'] for label in report if label not in ('accuracy', 'macro avg', 'weighted avg')],\n",
    "        [\"Recall\"] + [report[label]['recall'] for label in report if label not in ('accuracy', 'macro avg', 'weighted avg')],\n",
    "        [\"F1-Score\"] + [report[label]['f1-score'] for label in report if label not in ('accuracy', 'macro avg', 'weighted avg')],\n",
    "        [\"Support\"] + [report[label]['support'] for label in report if label not in ('accuracy', 'macro avg', 'weighted avg')]\n",
    "    ]\n",
    "\n",
    "    # Add macro and weighted averages\n",
    "    rows.append([\"Macro Avg\", report['macro avg']['precision'], report['macro avg']['recall'], report['macro avg']['f1-score'], report['macro avg']['support']])\n",
    "    rows.append([\"Weighted Avg\", report['weighted avg']['precision'], report['weighted avg']['recall'], report['weighted avg']['f1-score'], report['weighted avg']['support']])\n",
    "    rows.append([\"Accuracy\", \"\", \"\", report['accuracy'], \"\"])\n",
    "\n",
    "    print(tabulate(rows, headers=headers, tablefmt=\"grid\", floatfmt=\".2f\"))\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.hist(train_confidences, bins=50, alpha=0.6, label=\"Train (Member)\", color='blue')\n",
    "plt.hist(test_confidences, bins=50, alpha=0.6, label=\"Test (Non-Member)\", color='red')\n",
    "plt.axvline(train_mean_conf, color='blue', linestyle='dashed', linewidth=1, label=f\"Mean Train Confidence: {train_mean_conf:.2f}\")\n",
    "plt.axvline(test_mean_conf, color='red', linestyle='dashed', linewidth=1, label=f\"Mean Test Confidence: {test_mean_conf:.2f}\")\n",
    "plt.xlabel(\"Model Confidence Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.title(\"Attribute Inference Attack - Confidence Distribution\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attack achieved 47% accuracy, meaning it correctly inferred the income level of individuals nearly half the time. As the Income attribute has 8 levels, it is normal that the accuracy is lower. If the attack tried to guess randomly, it would be around 12,5% (1/8 *100). Therefore data is leaking. \n",
    "\n",
    "Also, the model showed higher confidence on training data (0.91) than test data (0.83), indicating a potential privacy risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.5.4 Find most exposed individuals and the analyzing the infered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #TODO: HUH? not used\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Add predictions and confidence to the test dataset for analysis\n",
    "vulnerable_data = X_test_attack.copy()\n",
    "vulnerable_data['True_Income'] = y_test_attack.values\n",
    "vulnerable_data['Predicted_Income'] = y_pred_attack\n",
    "\n",
    "# Calculate prediction correctness\n",
    "vulnerable_data['Correct_Prediction'] = (vulnerable_data['True_Income'] == vulnerable_data['Predicted_Income'])\n",
    "\n",
    "# Fidn top 20 most vulnerable individuals (highest confidence)\n",
    "most_vulnerable = vulnerable_data.sort_values(by='model_confidence', ascending=False).head(20)\n",
    "\n",
    "print(\"Most Vulnerable Individuals (Top 20 by Confidence Score):\")\n",
    "print(tabulate(most_vulnerable[['model_confidence', 'True_Income', 'Predicted_Income', 'Correct_Prediction']],\n",
    "               headers='keys', tablefmt='pretty'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 20 most vulnerable individuals had a model confidence of 1.0, meaning the model was completely certain about their predicted income. 16 out of 20 predictions were completely correct (80%), highlighting a significant privacy concern for these individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Applying Differential Privacy Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import opacus\n",
    "import numpy\n",
    "\n",
    "print(numpy.__version__) # min 1.21\n",
    "print(opacus.__version__) # min 1.3\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_important)\n",
    "X_test_scaled = scaler.transform(X_test_important)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_bal.values, dtype=torch.long)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_bal.values, dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 2)  # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "model = FeedForwardNN(input_dim=X_train_tensor.shape[1])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "privacy_engine = opacus.PrivacyEngine()\n",
    "model, optimizer, train_loader = privacy_engine.make_private_with_epsilon(\n",
    "    module=model,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_loader,\n",
    "    target_epsilon=5.0,     # Set desired privacy budget\n",
    "    target_delta=1e-5,\n",
    "    max_grad_norm=1.0,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "    predicted_classes = torch.argmax(predictions, dim=1)\n",
    "    acc = (predicted_classes == y_test_tensor).float().mean().item()\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "\n",
    "epsilon = privacy_engine.get_epsilon(delta=1e-5)\n",
    "print(f\"Final ε: {epsilon:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Evaluation & Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Results & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion & Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
