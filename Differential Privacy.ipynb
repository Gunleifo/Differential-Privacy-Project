{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Balancing Privacy and Accuracy in Machine Learning Models with Differential Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 . Introduction & Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project explores how **Differential Privacy Stochastic Gradient Descent (DP-SGD)** and **Model Agnostic Private Learning (MAPL)** impact machine learning models. Specifically, we examine whether DP techniques interfere with model accuracy and the evolution of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 . Setup - Install Required Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below if there are missing packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n",
    "# %pip install pandas\n",
    "# %pip install scikit-learn==1.3.2\n",
    "# %pip install ucimlrepo\n",
    "# %pip install imblearn\n",
    "# %pip install tabulate\n",
    "# %pip install boruta\n",
    "# %pip install torch\n",
    "# %pip install opacus\n",
    "# %pip install scipy\n",
    "# %pip install numpy\n",
    "# %pip install imbalanced-learn==0.11.0\n",
    "\n",
    "import importlib.util\n",
    "\n",
    "required = {\n",
    "    \"matplotlib\",\n",
    "    \"seaborn\",\n",
    "    \"pandas\",\n",
    "    \"ucimlrepo\",\n",
    "    \"tabulate\",\n",
    "    \"boruta\",\n",
    "    \"torch\",\n",
    "    \"opacus\",\n",
    "    \"scipy\",\n",
    "    \"numpy==1.26.4\",\n",
    "}\n",
    "\n",
    "installed = {pkg for pkg in required if importlib.util.find_spec(pkg.split('=')[0]) is not None}\n",
    "# Special handling for scikit-learn as it may be installed under the name 'sklearn'\n",
    "if importlib.util.find_spec(\"sklearn\") is not None:\n",
    "    installed.add(\"scikit-learn\")\n",
    "# Special handling for imbalanced-learn as it is installed under the name 'imblearn'\n",
    "if importlib.util.find_spec(\"imblearn\") is not None:\n",
    "    installed.add(\"imbalanced-learn\")\n",
    "missing = required - installed\n",
    "\n",
    "if missing:\n",
    "    print(f\"The following libraries are missing: {', '.join(missing)}\")\n",
    "    print(\"Attempting to install missing libraries...\")\n",
    "    %pip install {\" \".join(missing)}\n",
    "    print(\"Libraries installed successfully.\")\n",
    "else:\n",
    "    print(\"All required libraries are installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "def save_file(data, file_path, params={}):\n",
    "    if not os.path.exists(os.path.dirname(file_path)):\n",
    "        print(f\"Creating directory: {os.path.dirname(file_path)}\")\n",
    "        os.makedirs(os.path.dirname(file_path))\n",
    "    if file_path.endswith('.csv'):\n",
    "        data.to_csv(file_path, index=False, **params)\n",
    "    elif file_path.endswith('.png') or file_path.endswith('.jpg'):\n",
    "        data.savefig(file_path)\n",
    "    elif file_path.endswith('.pkl'):\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "    \n",
    "results_gInfo_dir = \"results/generalInfo\"\n",
    "results_fsData_dir = \"results/featureSelectionData\"\n",
    "results_models_dir = \"results/models\"\n",
    "models_dir = \"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 . Data Exploration & Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are importing the relevant libraries and getting the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ucimlrepo import fetch_ucirepo #to retrieve the dataset\n",
    "\n",
    "# Getting the data\n",
    "dataset_id = 891  # our chosen dataset\n",
    "dataset_name = \"dataset.csv\"\n",
    "downloaded = os.path.isfile(dataset_name)\n",
    "df =  pd.read_csv(dataset_name) if downloaded else fetch_ucirepo(id=dataset_id).data.original\n",
    "\n",
    "# # Previous way to retrieve the dataset (for documentation)\n",
    "# url = 'https://archive.ics.uci.edu/static/public/891/data.csv'\n",
    "# df = pd.read_csv(url)\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "if not downloaded:\n",
    "    print(\"Dataset not found locally. Downloading...\")\n",
    "    save_file(df, \"./\" + dataset_name)\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have observed that the dataset contains 253,680 records with 23 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking basic Dataset Information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have observed that all features are stored as integer data types:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table shows the features and their descriptions:\n",
    "\n",
    "| Variable Name     | Role    | Type    | Description                                                                 |\n",
    "|-------------------|---------|---------|-----------------------------------------------------------------------------|\n",
    "| ID                | ID      | Integer | Patient ID                                                                  |\n",
    "| Diabetes_binary   | Target  | Binary  | 0 = no diabetes 1 = prediabetes or diabetes                                 |\n",
    "| HighBP            | Feature | Binary  | 0 = no high BP 1 = high BP                                                  |\n",
    "| HighChol          | Feature | Binary  | 0 = no high cholesterol 1 = high cholesterol                                |\n",
    "| CholCheck         | Feature | Binary  | 0 = no cholesterol check in 5 years 1 = yes cholesterol check in 5 years    |\n",
    "| BMI               | Feature | Integer | Body Mass Index                                                             |\n",
    "| Smoker            | Feature | Binary  | Have you smoked at least 100 cigarettes in your entire life? [Note: 5 packs = 100 cigarettes] 0 = no 1 = yes |\n",
    "| Stroke            | Feature | Binary  | (Ever told) you had a stroke. 0 = no 1 = yes                                |\n",
    "| HeartDiseaseorAttack | Feature | Binary | coronary heart disease (CHD) or myocardial infarction (MI) 0 = no 1 = yes  |\n",
    "| PhysActivity      | Feature | Binary  | physical activity in past 30 days - not including job 0 = no 1 = yes        |\n",
    "| Fruits            | Feature | Binary  | Consume Fruit 1 or more times per day 0 = no 1 = yes                        |\n",
    "| Veggies           | Feature | Binary  | Consume Vegetables 1 or more times per day 0 = no 1 = yes                   |\n",
    "| HvyAlcoholConsump | Feature | Binary  | Heavy drinkers (adult men having more than 14 drinks per week and adult women having more than 7 drinks per week) 0 = no 1 = yes |\n",
    "| AnyHealthcare     | Feature | Binary  | Have any kind of health care coverage, including health insurance, prepaid plans such as HMO, etc. 0 = no 1 = yes |\n",
    "| NoDocbcCost       | Feature | Binary  | Was there a time in the past 12 months when you needed to see a doctor but could not because of cost? 0 = no 1 = yes |\n",
    "| GenHlth           | Feature | Integer | General health: 1 = excellent 2 = very good 3 = good 4 = fair 5 = poor |\n",
    "| MentHlth          | Feature | Integer | For how many days during the past 30 days was your mental health not good? scale 1-30 days |\n",
    "| PhysHlth          | Feature | Integer | For how many days during the past 30 days was your physical health not good? scale 1-30 days |\n",
    "| DiffWalk          | Feature | Binary  | Do you have serious difficulty walking or climbing stairs? 0 = no 1 = yes   |\n",
    "| Sex               | Feature | Binary  | 0 = female 1 = male                                                    |\n",
    "| Age               | Feature | Integer | 13 levels, 1 = 18-24, 9 = 60-64, 13 = 80 or older              |\n",
    "| Education         | Feature | Integer | 6 levels, 1 = Never attended school or only kindergarten, 2 = Grades 1 through 8, 3 = Grades 9 through 11, 4 = Grade 12 or GED, 5 = College 1 year to 3 years, 6 = College 4 years or more |\n",
    "| Income            | Feature | Integer | 8 levels, 1 = less than $10,000, 5 = less than $35,000, 8 = $75,000 or more |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data types\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have observed basic statistics for the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking basic statistics\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Save basic statistics to a CSV file\n",
    "save_file(df.describe(), os.path.join(results_gInfo_dir, \"basic_statistics.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have observed that there are no missing values (as stated in the dataset description):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "print(\"\\nMissing values per column:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have observed that the dataset only has 13.93% records with diabetes. We will address this imbalance later during data cleaning and preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking distribution of dataset\n",
    "diabetes_counts = df['Diabetes_binary'].value_counts()\n",
    "print(\"Distribution of target variable:\")\n",
    "print(diabetes_counts)\n",
    "print(f\"Percentage of records with diabetes: {diabetes_counts[1]/len(df)*100:.2f}%\")\n",
    "# Plot the distribution of the target variable\n",
    "plt.figure(figsize=(8, 6))\n",
    "diabetes_counts.plot(kind='bar', color=['skyblue', 'orange'])\n",
    "plt.title(\"Distribution of Target Variable (Diabetes_binary)\")\n",
    "plt.xlabel(\"Diabetes_binary\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(ticks=[0, 1], labels=[f\"No Diabetes ({diabetes_counts[0]:,})\", f\"Diabetes ({diabetes_counts[1]:,})\"], rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plot_path = os.path.join(results_gInfo_dir, \"imbalanced_diabetes_distribution.png\")\n",
    "save_file(plt, plot_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 . Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually in preprocessing we would handle missing values, encoding binary data (True -> 1), encoding categorical data, feature scaling. However, since the dataset is already clean and preprocessed, we will only address the class imbalance issue.\n",
    "In the balanced datased, we have reduced the number of records with diabetes to match the number of records without diabetes, so that the dataset is balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Class Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_with_diabetes = df['Diabetes_binary'].value_counts()[1]\n",
    "\n",
    "print(\"\\nOriginal Dataset:\")\n",
    "print(f\"- Total samples in the original dataset: {len(df)}\")\n",
    "print(f\"- Samples with diabetes (class 1): {num_with_diabetes}\")\n",
    "print(f\"- Samples without diabetes (class 0): {df['Diabetes_binary'].value_counts()[0]}\")\n",
    "\n",
    "df_no_diabetes = df[df['Diabetes_binary'] == 0].sample(n=num_with_diabetes, random_state=42)\n",
    "df_with_diabetes = df[df['Diabetes_binary'] == 1]\n",
    "\n",
    "df_balanced = pd.concat([df_no_diabetes, df_with_diabetes])\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df_balanced_noTarget = df_balanced.drop(columns=[\"Diabetes_binary\", \"ID\"])\n",
    "y_balanced = df_balanced[\"Diabetes_binary\"]\n",
    "\n",
    "print(\"\\nBalanced Dataset:\")\n",
    "print(f\"- Total samples in the balanced dataset: {len(df_balanced)}\")\n",
    "print(df_balanced['Diabetes_binary'].value_counts())\n",
    "\n",
    "print(f\"- Samples without diabetes (class 0): {df_balanced['Diabetes_binary'].value_counts()[0]}\")\n",
    "print(f\"- Samples with diabetes (class 1): {df_balanced['Diabetes_binary'].value_counts()[1]}\")\n",
    "\n",
    "# Plot the distribution of the balanced dataset\n",
    "plt.figure(figsize=(8, 6))\n",
    "df_balanced['Diabetes_binary'].value_counts().plot(kind='bar', color=['skyblue', 'orange'])\n",
    "plt.title(\"Distribution of Target Variable (Balanced Dataset)\")\n",
    "plt.xlabel(\"Diabetes_binary\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xticks(ticks=[0, 1], labels=[\"No Diabetes\", \"Diabetes\"], rotation=0)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plot_path_balanced = os.path.join(results_gInfo_dir, \"balanced_diabetes_distribution.png\")\n",
    "save_file(plt, plot_path_balanced)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Data Splitting Strategy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training our models we have to split the data into a training set and a test set. We have chosen a 80/20 split, which ensures we have enough training data for the model to learn patterns and enough data for performance evaluation. We have used stratified sampling to ensure that both the training set and test set includes a 50/50 split of records having diabetes or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_balanced = df_balanced.drop('Diabetes_binary', axis=1) # drop the target column\n",
    "y_balanced = df_balanced['Diabetes_binary']\n",
    "\n",
    "X_imbalanced = df.drop('Diabetes_binary', axis=1) #drop the target column\n",
    "y_imbalanced = df['Diabetes_binary']\n",
    "\n",
    "# split into train (70%) and temp (30%)\n",
    "X_train_bal, X_temp_bal, y_train_bal, y_temp_bal = train_test_split(\n",
    "    X_balanced, y_balanced, test_size=0.3, random_state=42, stratify=y_balanced\n",
    ")\n",
    "\n",
    "# split temp set into validation (10%) and test (20%)\n",
    "X_val_bal, X_test_bal, y_val_bal, y_test_bal = train_test_split(\n",
    "    X_temp_bal, y_temp_bal, test_size=2/3, random_state=42, stratify=y_temp_bal\n",
    ")\n",
    "\n",
    "# Imbalanced dataset\n",
    "X_train_imb, X_temp_imb, y_train_imb, y_temp_imb = train_test_split(\n",
    "    X_imbalanced, y_imbalanced, test_size=0.3, random_state=42, stratify=y_imbalanced\n",
    ")\n",
    "\n",
    "X_val_imb, X_test_imb, y_val_imb, y_test_imb = train_test_split(\n",
    "    X_temp_imb, y_temp_imb, test_size=2/3, random_state=42, stratify=y_temp_imb\n",
    ")\n",
    "\n",
    "print(f\"Balanced Training set: {X_train_bal.shape[0]} samples\")\n",
    "print(f\"Balanced Validation set: {X_val_bal.shape[0]} samples\")\n",
    "print(f\"Balanced Testing set: {X_test_bal.shape[0]} samples\")\n",
    "\n",
    "print(\"\\nClass distribution in balanced training set:\")\n",
    "print(y_train_bal.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nClass distribution in balanced validation set:\")\n",
    "print(y_val_bal.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nClass distribution in balanced testing set:\")\n",
    "print(y_test_bal.value_counts(normalize=True))\n",
    "\n",
    "print(f\"\\nImbalanced Training set: {X_train_imb.shape[0]} samples\")\n",
    "print(f\"Imbalanced Validation set: {X_val_imb.shape[0]} samples\")\n",
    "print(f\"Imbalanced Testing set: {X_test_imb.shape[0]} samples\")\n",
    "\n",
    "print(\"\\nClass distribution in imbalanced training set:\")\n",
    "print(y_train_imb.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nClass distribution in imbalanced validation set:\")\n",
    "print(y_val_imb.value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nClass distribution in imbalanced testing set:\")\n",
    "print(y_test_imb.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This might be a defense against the attacks, because the less features we have, the less information we leak.\n",
    "\n",
    "We need to explain which features we have chosen based on the data exploration above and the following feature selection methods. We can use variance threshold, correlation matrix, kbest, rfe, boruta...\n",
    "\n",
    "['HighBP', 'HighChol', 'BMI', 'GenHlth', 'Age'] ok with V.T. and C.M.\n",
    "\n",
    "Might want to use more features to try the attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import (\n",
    "    RFE,\n",
    "    SelectKBest,\n",
    "    VarianceThreshold,\n",
    "    mutual_info_classif,\n",
    ")\n",
    "from boruta import BorutaPy\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, classification_report\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "\n",
    "def save_results(results, file_path, columns):\n",
    "    results_df = pd.DataFrame(results, columns=columns)\n",
    "    if not os.path.exists(os.path.dirname(file_path)):\n",
    "        os.makedirs(os.path.dirname(file_path))\n",
    "    results_df.to_csv(file_path, index=False)\n",
    "\n",
    "def calculate_metrics(y_test, y_pred):\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    return (accuracy, precision, recall, f1)\n",
    "\n",
    "def getVariances(threshold, data):\n",
    "    var_threshold = VarianceThreshold(threshold=threshold)\n",
    "    var_threshold.fit(data)\n",
    "    variances = var_threshold.variances_\n",
    "    # Create a DataFrame for variances\n",
    "    variances_df = pd.DataFrame(variances, index=data.columns, columns=[\"Variance\"])\n",
    "    # Sort variances in descending order\n",
    "    variances_df = variances_df.sort_values(by=\"Variance\", ascending=False)\n",
    "    # Features with variance >= threshold\n",
    "    features_high_variance = variances_df[variances_df[\"Variance\"] >= threshold]\n",
    "    # Features with variance < threshold\n",
    "    features_low_variance = variances_df[variances_df[\"Variance\"] < threshold]\n",
    "    return variances_df, features_high_variance, features_low_variance\n",
    "\n",
    "def getKBest(k, data, target):\n",
    "    # selection\n",
    "    selector = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "    x_kbest = selector.fit_transform(data, target)\n",
    "    # Create a DataFrame with the selected features\n",
    "    kbest_features = data.columns[selector.get_support()]\n",
    "    x_kbest_df = pd.DataFrame(x_kbest, columns=kbest_features)\n",
    "    return x_kbest_df\n",
    "\n",
    "def process_kbest(data, target, k, file_path):\n",
    "    try:\n",
    "        x_kbest_df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        x_kbest_df = getKBest(k, data, target)\n",
    "        x_kbest_df[target.name] = target.values\n",
    "        x_kbest_df.to_csv(file_path, index=False)\n",
    "    x_kbest_df = x_kbest_df.drop(columns=[target.name], axis=1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x_kbest_df, target, test_size=0.3, random_state=42, stratify=target\n",
    "    )\n",
    "    rf_model.fit(x_train, y_train)\n",
    "    y_pred = rf_model.predict(x_test)\n",
    "    accuracy, precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
    "    kbest_features_names = x_kbest_df.columns.tolist()\n",
    "    return (k, accuracy, precision, recall, f1, kbest_features_names)\n",
    "\n",
    "def getRFE(k, data, target):\n",
    "    # selection\n",
    "    selector = RFE(estimator=rf_model, n_features_to_select=k)\n",
    "    x_rfe = selector.fit_transform(data, target)\n",
    "    # Create a DataFrame with the selected features\n",
    "    rfe_features = data.columns[selector.get_support()]\n",
    "    x_rfe_df = pd.DataFrame(x_rfe, columns=rfe_features)\n",
    "    return x_rfe_df\n",
    "\n",
    "def process_rfe(data, target, k, file_path):\n",
    "    try:\n",
    "        x_rfe_df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        x_rfe_df = getRFE(k, data, target)\n",
    "        x_rfe_df[target.name] = target.values\n",
    "        x_rfe_df.to_csv(file_path, index=False)\n",
    "    x_rfe_df = x_rfe_df.drop(columns=[target.name], axis=1)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        x_rfe_df, target, test_size=0.3, random_state=42, stratify=target\n",
    "    )\n",
    "    rf_model.fit(x_train, y_train)\n",
    "    y_pred = rf_model.predict(x_test)\n",
    "    accuracy, precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
    "    rfe_features_names = x_rfe_df.columns.tolist()\n",
    "    return (k, accuracy, precision, recall, f1, rfe_features_names)\n",
    "\n",
    "def apply_boruta(data, target):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        data, target, test_size=0.3, random_state=42, stratify=target\n",
    "    )\n",
    "    boruta = BorutaPy(\n",
    "        rf_model,\n",
    "        n_estimators=\"auto\",\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "    )\n",
    "    boruta.fit(x_train.values, y_train.values)\n",
    "    sel_x_train = boruta.transform(x_train.values)\n",
    "    sel_x_test = boruta.transform(x_test.values)\n",
    "    rf_model.fit(sel_x_train, y_train)\n",
    "    y_pred = rf_model.predict(sel_x_test)\n",
    "    accuracy, precision, recall, f1 = calculate_metrics(y_test, y_pred)\n",
    "    selected_features = x_train.columns[boruta.support_].tolist()\n",
    "    return (accuracy, precision, recall, f1, selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variances_df, features_high_variance, features_low_variance = getVariances(\n",
    "    0, df_balanced_noTarget\n",
    ")\n",
    "\n",
    "# Plot variances of all features\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(variances_df.index, variances_df['Variance'], color='skyblue')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Variance')\n",
    "plt.title('Feature Variances')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Highlight features with high and low variance\n",
    "print(\"\\nFeatures with High Variance:\")\n",
    "print(features_high_variance)\n",
    "print(\"\\nFeatures with Low Variance:\")\n",
    "print(features_low_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = df_balanced.corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Focus on correlations with the target variable\n",
    "diabetes_correlations = correlation_matrix['Diabetes_binary'].sort_values(ascending=False)\n",
    "print(\"\\nFeatures correlated with Diabetes (sorted):\")\n",
    "print(diabetes_correlations)\n",
    "\n",
    "# Visualize correlations with the target\n",
    "plt.figure(figsize=(12, 8))\n",
    "diabetes_correlations[1:].plot(kind='bar')  # Exclude self-correlation\n",
    "plt.title(\"Feature Correlation with Diabetes\")\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Correlation Coefficient\")\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.3 KBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# columns = [\"Model\", \"K\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Features\"]\n",
    "# for k in range(1, df_balanced_noTarget.shape[1] + 1):\n",
    "#     file_path = f\"featureSelectionData/kbest/k/{k}best_features.csv\"\n",
    "#     kbestResult = process_kbest(df_balanced_noTarget, y_balanced, k, file_path)\n",
    "#     results.append((\"rf\",) + kbestResult)\n",
    "# save_results(\n",
    "#     results, f\"featureSelectionData/kbest/kbest_rf_results.csv\", columns\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.4 RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# columns = [\"Model\", \"K\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Features\"]\n",
    "# for k in range(1, df_balanced_noTarget.shape[1] + 1):\n",
    "#     file_path = f\"featureSelectionData/rfe/k/{k}rfe_features.csv\"\n",
    "#     rfeResult = process_rfe(df_balanced_noTarget, y_balanced, k, file_path)\n",
    "#     results.append((\"rf\",) + rfeResult)\n",
    "# save_results(results, f\"featureSelectionData/rfe/rfe_rf_results.csv\", columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.5 Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"Features\"]\n",
    "# accuracy, precision, recall, f1, selected_features = apply_boruta(\n",
    "#     df_balanced_noTarget, y_balanced\n",
    "# )\n",
    "# save_results(\n",
    "#     [(\"rf\", accuracy, precision, recall, f1, selected_features)],\n",
    "#     f\"featureSelectionData/boruta/boruta_rf_results.csv\",\n",
    "#     columns,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Tuning model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# params = {\n",
    "#     'max_depth': [2,3,5,10,20],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [5,10,20,50,100,200],\n",
    "#     'n_estimators': [50,100,150,200]\n",
    "# }\n",
    "\n",
    "# # Instantiate the grid search model\n",
    "# grid_search = GridSearchCV(estimator=rf_model,\n",
    "#                            param_grid=params,\n",
    "#                            cv = 4,\n",
    "#                            n_jobs=-1, verbose=1, scoring=\"precision\")\n",
    "\n",
    "# important_features = ['HighBP', 'HighChol', 'BMI', 'GenHlth', 'Age', 'Income']\n",
    "# X_train_important = X_train_bal[important_features]\n",
    "\n",
    "# grid_search.fit(X_train_important, y_train_bal)\n",
    "# print(\"\\nBest parameters found: \", grid_search.best_estimator_)\n",
    "# rf_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 . Machine Learning Model without Differential Privacy\n",
    "\n",
    "- Precision: How many predicted positives are actually positive?\n",
    "- Recall: How many actual positives were correctly identified?\n",
    "- F1-score: A balance between precision and recall.\n",
    "- Support: Number of actual occurrences of each class.\n",
    "\n",
    "Single-layer networks have just one layer of active units. Inputs connect directly to the outputs through a single layer of weights.\n",
    "\n",
    "In multi-layer networks (MLP) there is a layer of input nodes, a layer of output nodes, and one or more intermediate (hidden) layers.\n",
    "\n",
    "- Input Layer: Input variables, sometimes called the visible layer.\n",
    "- Hidden Layers: Layers of nodes between the input and output layers. There may be one or more of these layers.\n",
    "- Output Layer: A layer of nodes that produce the output variables.\n",
    "- Size: The number of nodes in the model.\n",
    "- Width: The number of nodes in a specific layer.\n",
    "- Depth: The number of layers in a neural network.\n",
    "\n",
    "The structure of an MLP can be summarized using a simple notation: the number of nodes in each layer is specified as an integer, in order from the input layer to the output layer, with the size of each layer separated by a \"/\". For example, a model with 3 input nodes, 2 hidden layers with 4 and 3 nodes respectively, and 1 output node would be represented as \"3/4/3/1\".\n",
    "\n",
    "Steps to train a deep learning model with pytorch:\n",
    "1. Scale the data\n",
    "2. Label encode the target\n",
    "3. Convert the data to tensors\n",
    "4. Create a model\n",
    "   1. Should we use a wide model or a deep model? \n",
    "   2. How many layers and neurons per layer should we use?\n",
    "   3. How to choose? K-fold cross validaton\n",
    "5. Train the model\n",
    "\n",
    "K-fold cross validaton is a technique that, use a “training set” of data to train the model and then use a “test set” of data to see how accurate the model can predict. The result from test set is what we should focus on. But we do not want to test a model once because if we see an extremely good or bad result, it may be by chance. we want to run this process times with different training and test sets, such that we are ensured that we are comparing the model design, not the result of a particular training. K-fold cross validaton splits a larger dataset into portions and take one portion as the test set while the portions are combined as the training set. There are different such combinations. Therefore we can repeat the experiment for times and take the average result. To ensure that each portion contains equal number of classes we will use stratified k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "models_performance_path = os.path.join(results_models_dir, 'models_performance.csv')\n",
    "\n",
    "# Define the model\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, 2)  # Binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "def get_train_test_tensors(X_train, y_train, X_test, y_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "    \n",
    "    return X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor\n",
    "\n",
    "def getLoader(X_train_tensor, y_train_tensor):\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "    return train_loader\n",
    "\n",
    "def save_model_performance(classification_report_dict, model_name):\n",
    "    performance = {\n",
    "        \"Model\": model_name,\n",
    "        \"Accuracy\": classification_report_dict[\"accuracy\"],\n",
    "        \"Precision_0\": classification_report_dict[\"0\"][\"precision\"],\n",
    "        \"Precision_1\": classification_report_dict[\"1\"][\"precision\"],\n",
    "        \"Precision_weighted\": classification_report_dict[\"weighted avg\"][\"precision\"],\n",
    "        \"Recall_0\": classification_report_dict[\"0\"][\"recall\"],\n",
    "        \"Recall_1\": classification_report_dict[\"1\"][\"recall\"],\n",
    "        \"Recall_weighted\": classification_report_dict[\"weighted avg\"][\"recall\"],\n",
    "        \"F1_0\": classification_report_dict[\"0\"][\"f1-score\"],\n",
    "        \"F1_1\": classification_report_dict[\"1\"][\"f1-score\"],\n",
    "        \"F1_weighted\": classification_report_dict[\"weighted avg\"][\"f1-score\"],\n",
    "        \"Support_0\": classification_report_dict[\"0\"][\"support\"],\n",
    "        \"Support_1\": classification_report_dict[\"1\"][\"support\"],\n",
    "        \"Support_weighted\": classification_report_dict[\"weighted avg\"][\"support\"],\n",
    "    }\n",
    "    if os.path.isfile(models_performance_path,):\n",
    "        existing_data = pd.read_csv(models_performance_path)\n",
    "        if performance[\"Model\"] not in existing_data[\"Model\"].values:\n",
    "            save_file(pd.DataFrame([performance]), models_performance_path, {'mode': 'a', 'header': False})\n",
    "        else:\n",
    "            existing_data.loc[existing_data[\"Model\"] == performance[\"Model\"], :] = pd.DataFrame([performance]).values\n",
    "            save_file(existing_data, models_performance_path)\n",
    "    else:\n",
    "        save_file(pd.DataFrame([performance]), models_performance_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Using all features (balanced dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to tensors PyTorch tensors as this is the format a PyTorch model needs\n",
    "train_test_tensors_allF_bal = get_train_test_tensors(X_train_bal, y_train_bal, \n",
    "                                                     X_test_bal, y_test_bal)\n",
    "X_train_tensor_allF_bal = train_test_tensors_allF_bal[0]\n",
    "y_train_tensor_allF_bal = train_test_tensors_allF_bal[1]\n",
    "X_test_tensor_allF_bal = train_test_tensors_allF_bal[2]\n",
    "y_test_tensor_allF_bal = train_test_tensors_allF_bal[3]\n",
    "\n",
    "train_loader_allF_bal = getLoader(X_train_tensor_allF_bal, y_train_tensor_allF_bal)\n",
    "\n",
    "model_allF_bal = FeedForwardNN(input_dim=X_train_tensor_allF_bal.shape[1])\n",
    "optimizer_allF_bal = torch.optim.SGD(model_allF_bal.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "print(\"Training neural network model...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model_allF_bal.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader_allF_bal:\n",
    "        optimizer_allF_bal.zero_grad()\n",
    "        output = model_allF_bal(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer_allF_bal.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader_allF_bal):.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model_allF_bal.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_allF_bal(X_test_tensor_allF_bal)\n",
    "    predicted_classes = torch.argmax(predictions, dim=1)\n",
    "    \n",
    "    # Convert to numpy for sklearn metrics\n",
    "    y_pred = predicted_classes.numpy()\n",
    "    y_true = y_test_tensor_allF_bal.numpy()\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "save_file(model_allF_bal, os.path.join(models_dir, 'deepL_allF_bal_model.pkl'))\n",
    "# Save model performance\n",
    "classification_report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "save_model_performance(classification_report_dict, 'deepL_allF_bal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Using manually selected features (balanced dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define important features\n",
    "manual_important_features = ['GenHlth', 'HighBP', 'DiffWalk', 'BMI', 'HighChol', 'Age', \n",
    "                      'HeartDiseaseorAttack', 'PhysHlth', 'Stroke', 'MentHlth', \n",
    "                      'CholCheck', 'Smoker', 'NoDocbcCost', 'Sex', 'AnyHealthcare', \n",
    "                      'Income', 'Education']\n",
    "\n",
    "X_train_bal_manSelF = X_train_bal[manual_important_features]\n",
    "X_test_bal_manSelF = X_test_bal[manual_important_features]\n",
    "train_test_tensors_manSelF_bal = get_train_test_tensors(X_train_bal_manSelF, y_train_bal,\n",
    "                                                     X_test_bal_manSelF, y_test_bal)\n",
    "X_train_tensor_manSelF_bal = train_test_tensors_manSelF_bal[0]\n",
    "y_train_tensor_manSelF_bal = train_test_tensors_manSelF_bal[1]\n",
    "X_test_tensor_manSelF_bal = train_test_tensors_manSelF_bal[2]\n",
    "y_test_tensor_manSelF_bal = train_test_tensors_manSelF_bal[3]\n",
    "\n",
    "train_loader_manSelF_bal = getLoader(X_train_tensor_manSelF_bal, y_train_tensor_manSelF_bal)\n",
    "\n",
    "model_manSelF_bal = FeedForwardNN(input_dim=X_train_tensor_manSelF_bal.shape[1])\n",
    "optimizer_manSelF_bal = torch.optim.SGD(model_manSelF_bal.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "print(\"Training neural network model with important features...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model_manSelF_bal.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader_manSelF_bal:\n",
    "        optimizer_manSelF_bal.zero_grad()\n",
    "        output = model_manSelF_bal(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer_manSelF_bal.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader_manSelF_bal):.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model_manSelF_bal.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_manSelF_bal(X_test_tensor_manSelF_bal)\n",
    "    predicted_classes = torch.argmax(predictions, dim=1)\n",
    "    \n",
    "    # Convert to numpy for sklearn metrics\n",
    "    y_pred = predicted_classes.numpy()\n",
    "    y_true = y_test_tensor_manSelF_bal.numpy()\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "save_file(model_manSelF_bal, os.path.join(models_dir, 'deepL_manSelF_bal_model.pkl'))\n",
    "# Save model performance\n",
    "classification_report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "save_model_performance(classification_report_dict, 'deepL_manSelF_bal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Using selected features (balanced dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the smaller set of important features\n",
    "important_features = ['HighBP', 'HighChol', 'BMI', 'GenHlth', 'Age', 'Income']\n",
    "\n",
    "X_train_bal_selF = X_train_bal[important_features]\n",
    "X_test_bal_selF = X_test_bal[important_features]\n",
    "train_test_tensors_selF_bal = get_train_test_tensors(X_train_bal_selF, y_train_bal,\n",
    "                                                     X_test_bal_selF, y_test_bal)\n",
    "X_train_tensor_selF_bal = train_test_tensors_selF_bal[0]\n",
    "y_train_tensor_selF_bal = train_test_tensors_selF_bal[1]\n",
    "X_test_tensor_selF_bal = train_test_tensors_selF_bal[2]\n",
    "y_test_tensor_selF_bal = train_test_tensors_selF_bal[3]\n",
    "\n",
    "train_loader_selF_bal = getLoader(X_train_tensor_selF_bal, y_train_tensor_selF_bal)\n",
    "\n",
    "model_selF_bal = FeedForwardNN(input_dim=X_train_tensor_selF_bal.shape[1])\n",
    "optimizer_selF_bal = torch.optim.SGD(model_selF_bal.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "print(\"Training neural network model with selected features...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model_selF_bal.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader_selF_bal:\n",
    "        optimizer_selF_bal.zero_grad()\n",
    "        output = model_selF_bal(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer_selF_bal.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader_selF_bal):.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model_selF_bal.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_selF_bal(X_test_tensor_selF_bal)\n",
    "    predicted_classes = torch.argmax(predictions, dim=1)\n",
    "    \n",
    "    # Convert to numpy for sklearn metrics\n",
    "    y_pred = predicted_classes.numpy()\n",
    "    y_true = y_test_tensor_selF_bal.numpy()\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "save_file(model_selF_bal, os.path.join(models_dir, 'deepL_selF_bal_model.pkl'))\n",
    "# Save model performance\n",
    "classification_report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "save_model_performance(classification_report_dict, 'deepL_selF_bal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Using selected features (imbalanced dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model over prioritizes the majority class (0 - no diabetes), as it was trained with the imbalanced data.**\n",
    "\n",
    "Comparison:\n",
    "\n",
    "Balanced data (6.2) - Lower accuracy (74%) but much better at detecting class 1 - diabetes (79%), as it gives the same importance to both classes.\n",
    "\n",
    "Imbalanced data (6.3) - Higher accuracy (86%) but poor detection of class 1 - diabetes (16%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the imbalanced training and test sets to include only important features\n",
    "X_train_imb_selF = X_train_imb[important_features]\n",
    "X_test_imb_selF = X_test_imb[important_features]\n",
    "train_test_tensors_selF_imb = get_train_test_tensors(X_train_imb_selF, y_train_imb,\n",
    "                                                     X_test_imb_selF, y_test_imb)\n",
    "X_train_tensor_selF_imb = train_test_tensors_selF_imb[0]\n",
    "y_train_tensor_selF_imb = train_test_tensors_selF_imb[1]\n",
    "X_test_tensor_selF_imb = train_test_tensors_selF_imb[2]\n",
    "y_test_tensor_selF_imb = train_test_tensors_selF_imb[3]\n",
    "\n",
    "train_loader_selF_imb = getLoader(X_train_tensor_selF_imb, y_train_tensor_selF_imb)\n",
    "\n",
    "model_selF_imb = FeedForwardNN(input_dim=X_train_tensor_selF_imb.shape[1])\n",
    "optimizer_selF_imb = torch.optim.SGD(model_selF_imb.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "print(\"Training neural network model with selected features on imbalanced data...\")\n",
    "for epoch in range(num_epochs):\n",
    "    model_selF_imb.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader_selF_imb:\n",
    "        optimizer_selF_imb.zero_grad()\n",
    "        output = model_selF_imb(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer_selF_imb.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader_selF_imb):.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model_selF_imb.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_selF_imb(X_test_tensor_selF_imb)\n",
    "    predicted_classes = torch.argmax(predictions, dim=1)\n",
    "    \n",
    "    # Convert to numpy for sklearn metrics\n",
    "    y_pred = predicted_classes.numpy()\n",
    "    y_true = y_test_tensor_selF_imb.numpy()\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    \n",
    "    # Check class distribution in predictions\n",
    "    unique, counts = np.unique(y_pred, return_counts=True)\n",
    "    pred_distribution = dict(zip(unique, counts))\n",
    "    print(f\"Prediction distribution: {pred_distribution}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "save_file(model_selF_imb, os.path.join(models_dir, 'deepL_selF_imb_model.pkl'))\n",
    "# Save model performance\n",
    "classification_report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "save_model_performance(classification_report_dict, 'deepL_selF_imb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.1 Using validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter datasets to include only important features\n",
    "X_train_bal_selF = X_train_bal[important_features]\n",
    "X_test_bal_selF = X_test_bal[important_features]\n",
    "X_val_bal_selF = X_val_bal[important_features]\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled_selF = scaler.fit_transform(X_train_bal_selF)\n",
    "X_test_scaled_selF = scaler.transform(X_test_bal_selF)\n",
    "X_val_scaled_selF = scaler.transform(X_val_bal_selF)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor_selF = torch.tensor(X_train_scaled_selF, dtype=torch.float32)\n",
    "y_train_tensor_selF = torch.tensor(y_train_bal.values, dtype=torch.long)\n",
    "\n",
    "X_test_tensor_selF = torch.tensor(X_test_scaled_selF, dtype=torch.float32)\n",
    "y_test_tensor_selF = torch.tensor(y_test_bal.values, dtype=torch.long)\n",
    "\n",
    "X_val_tensor_selF = torch.tensor(X_val_scaled_selF, dtype=torch.float32)\n",
    "y_val_tensor_selF = torch.tensor(y_val_bal.values, dtype=torch.long)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "train_dataset_selF = TensorDataset(X_train_tensor_selF, y_train_tensor_selF)\n",
    "train_loader_selF = DataLoader(train_dataset_selF, batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize model with input dimension matching the number of selected features\n",
    "model_selF = FeedForwardNN(input_dim=len(important_features))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_selF = torch.optim.SGD(model_selF.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 5\n",
    "print(\"Training neural network model with selected features and validation...\")\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model_selF.train()\n",
    "    running_loss = 0.0\n",
    "    for X_batch, y_batch in train_loader_selF:\n",
    "        optimizer_selF.zero_grad()\n",
    "        output = model_selF(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer_selF.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Validation\n",
    "    model_selF.eval()\n",
    "    with torch.no_grad():\n",
    "        val_output = model_selF(X_val_tensor_selF)\n",
    "        val_loss = criterion(val_output, y_val_tensor_selF)\n",
    "        val_predicted = torch.argmax(val_output, dim=1)\n",
    "        val_acc = (val_predicted == y_val_tensor_selF).float().mean().item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {running_loss/len(train_loader_selF):.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# Final evaluation on test set\n",
    "model_selF.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_selF(X_test_tensor_selF)\n",
    "    predicted_classes = torch.argmax(predictions, dim=1)\n",
    "    \n",
    "    # Convert to numpy for sklearn metrics\n",
    "    y_pred = predicted_classes.numpy()\n",
    "    y_true = y_test_tensor_selF.numpy()\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    test_acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"\\nBalanced Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nBalanced Test Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Evaluate validation set\n",
    "with torch.no_grad():\n",
    "    val_predictions = model_selF(X_val_tensor_selF)\n",
    "    val_predicted_classes = torch.argmax(val_predictions, dim=1)\n",
    "    \n",
    "    # Convert to numpy for sklearn metrics\n",
    "    y_pred_val = val_predicted_classes.numpy()\n",
    "    y_val_true = y_val_tensor_selF.numpy()\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    val_acc = accuracy_score(y_val_true, y_pred_val)\n",
    "    print(f\"\\nBalanced Validation Accuracy: {val_acc:.4f}\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nBalanced Validation Classification Report:\")\n",
    "    print(classification_report(y_val_true, y_pred_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.2 Using SMOTE balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: put smote balancing in preprocessing?\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "X = df[important_features]\n",
    "y = df['Diabetes_binary']\n",
    "\n",
    "# Handle class imbalance using SMOTE\n",
    "# SMOTE balances the dataset by generating synthetic samples for the minority class\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "print(\"Before SMOTE:\", Counter(y))  # Shows original class distribution\n",
    "print(\"After SMOTE:\", Counter(y_resampled))  # Shows balanced class distribution\n",
    "\n",
    "print(\"Original dataset shape:\", X.shape, y.shape)\n",
    "print(\"Resampled dataset shape:\", X_resampled.shape, y_resampled.shape)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42, stratify=y_resampled)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=2/3, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Train with the balanced dataset split\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Checking accuracy and classification report\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 Applying Differential Privacy Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.1 Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import opacus\n",
    "\n",
    "print(np.__version__) # min 1.21\n",
    "print(opacus.__version__) # min 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.5.1.1 allF_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_tensors_allF_bal = get_train_test_tensors(X_train_bal, y_train_bal, \n",
    "                                                     X_test_bal, y_test_bal)\n",
    "X_train_tensor_allF_bal = train_test_tensors_allF_bal[0]\n",
    "y_train_tensor_allF_bal = train_test_tensors_allF_bal[1]\n",
    "X_test_tensor_allF_bal = train_test_tensors_allF_bal[2]\n",
    "y_test_tensor_allF_bal = train_test_tensors_allF_bal[3]\n",
    "\n",
    "train_loader_allF_bal = getLoader(X_train_tensor_allF_bal, y_train_tensor_allF_bal)\n",
    "\n",
    "model_allF_bal = FeedForwardNN(input_dim=X_train_tensor_allF_bal.shape[1])\n",
    "optimizer_allF_bal = torch.optim.SGD(model_allF_bal.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "privacy_engine = opacus.PrivacyEngine()\n",
    "model_allF_bal, optimizer_allF_bal, train_loader_allF_bal = privacy_engine.make_private_with_epsilon(\n",
    "    module=model_allF_bal,\n",
    "    optimizer=optimizer_allF_bal,\n",
    "    data_loader=train_loader_allF_bal,\n",
    "    target_epsilon=5.0,     # Set desired privacy budget\n",
    "    target_delta=1e-5,\n",
    "    max_grad_norm=1.0,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model_allF_bal.train()\n",
    "for epoch in range(5):\n",
    "    for X_batch, y_batch in train_loader_allF_bal:\n",
    "        optimizer_allF_bal.zero_grad()\n",
    "        output = model_allF_bal(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer_allF_bal.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "# Evaluate the model\n",
    "model_allF_bal.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_allF_bal(X_test_tensor_allF_bal)\n",
    "    predicted_classes = torch.argmax(predictions, dim=1)\n",
    "    # Convert to numpy for sklearn metrics\n",
    "    y_pred = predicted_classes.numpy()\n",
    "    y_true = y_test_tensor_allF_bal.numpy()\n",
    "    # Calculate accuracy\n",
    "    acc_allF_bal = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy (all features): {acc_allF_bal:.4f}\")\n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "\n",
    "epsilon = privacy_engine.get_epsilon(delta=1e-5)\n",
    "print(f\"Final ε: {epsilon:.2f}\")\n",
    "\n",
    "save_file(model_allF_bal, os.path.join(models_dir, 'deepL_allF_bal_dp_model.pkl'))\n",
    "# Save model performance\n",
    "classification_report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "save_model_performance(classification_report_dict, 'deepL_allF_bal_dp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.5.1.2 selF_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bal_selF = X_train_bal[important_features]\n",
    "X_test_bal_selF = X_test_bal[important_features]\n",
    "train_test_tensors_selF_bal = get_train_test_tensors(X_train_bal_selF, y_train_bal,\n",
    "                                                     X_test_bal_selF, y_test_bal)\n",
    "X_train_tensor_selF_bal = train_test_tensors_selF_bal[0]\n",
    "y_train_tensor_selF_bal = train_test_tensors_selF_bal[1]\n",
    "X_test_tensor_selF_bal = train_test_tensors_selF_bal[2]\n",
    "y_test_tensor_selF_bal = train_test_tensors_selF_bal[3]\n",
    "\n",
    "train_loader_selF_bal = getLoader(X_train_tensor_selF_bal, y_train_tensor_selF_bal)\n",
    "\n",
    "model_selF_bal = FeedForwardNN(input_dim=X_train_tensor_selF_bal.shape[1])\n",
    "optimizer_selF_bal = torch.optim.SGD(model_selF_bal.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "privacy_engine = opacus.PrivacyEngine()\n",
    "model_selF_bal, optimizer_selF_bal, train_loader_selF_bal = privacy_engine.make_private_with_epsilon(\n",
    "    module=model_selF_bal,\n",
    "    optimizer=optimizer_selF_bal,\n",
    "    data_loader=train_loader_selF_bal,\n",
    "    target_epsilon=5.0,     # Set desired privacy budget\n",
    "    target_delta=1e-5,\n",
    "    max_grad_norm=1.0,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model_selF_bal.train()\n",
    "for epoch in range(5):\n",
    "    for X_batch, y_batch in train_loader_selF_bal:\n",
    "        optimizer_selF_bal.zero_grad()\n",
    "        output = model_selF_bal(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer_selF_bal.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "# Evaluate the model\n",
    "model_selF_bal.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_selF_bal(X_test_tensor_selF_bal)\n",
    "    predicted_classes = torch.argmax(predictions, dim=1)\n",
    "    # Convert to numpy for sklearn metrics\n",
    "    y_pred = predicted_classes.numpy()\n",
    "    y_true = y_test_tensor_selF_bal.numpy()\n",
    "    # Calculate accuracy\n",
    "    acc_selF_bal = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy (selected features): {acc_selF_bal:.4f}\")\n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "epsilon = privacy_engine.get_epsilon(delta=1e-5)\n",
    "print(f\"Final ε: {epsilon:.2f}\")\n",
    "\n",
    "save_file(model_selF_bal, os.path.join(models_dir, 'deepL_selF_bal_dp_model.pkl'))\n",
    "# Save model performance\n",
    "classification_report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "save_model_performance(classification_report_dict, 'deepL_selF_bal_dp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.5.1.3 manSelF_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bal_manSelF = X_train_bal[manual_important_features]\n",
    "X_test_bal_manSelF = X_test_bal[manual_important_features]\n",
    "train_test_tensors_manSelF_bal = get_train_test_tensors(X_train_bal_manSelF, y_train_bal, \n",
    "                                                        X_test_bal_manSelF, y_test_bal)\n",
    "X_train_tensor_manSelF_bal = train_test_tensors_manSelF_bal[0]\n",
    "y_train_tensor_manSelF_bal = train_test_tensors_manSelF_bal[1]\n",
    "X_test_tensor_manSelF_bal = train_test_tensors_manSelF_bal[2]\n",
    "y_test_tensor_manSelF_bal = train_test_tensors_manSelF_bal[3]\n",
    "\n",
    "train_loader_manSelF_bal = getLoader(X_train_tensor_manSelF_bal, y_train_tensor_manSelF_bal)\n",
    "\n",
    "model_manSelF_bal = FeedForwardNN(input_dim=X_train_tensor_manSelF_bal.shape[1])\n",
    "optimizer_manSelF_bal = torch.optim.SGD(model_manSelF_bal.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "privacy_engine = opacus.PrivacyEngine()\n",
    "model_manSelF_bal, optimizer_manSelF_bal, train_loader_manSelF_bal = privacy_engine.make_private_with_epsilon(\n",
    "    module=model_manSelF_bal,\n",
    "    optimizer=optimizer_manSelF_bal,\n",
    "    data_loader=train_loader_manSelF_bal,\n",
    "    target_epsilon=5.0,     # Set desired privacy budget\n",
    "    target_delta=1e-5,\n",
    "    max_grad_norm=1.0,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model_manSelF_bal.train()\n",
    "for epoch in range(5):\n",
    "    for X_batch, y_batch in train_loader_manSelF_bal:\n",
    "        optimizer_manSelF_bal.zero_grad()\n",
    "        output = model_manSelF_bal(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer_manSelF_bal.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "# Evaluate the model\n",
    "model_manSelF_bal.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model_manSelF_bal(X_test_tensor_manSelF_bal)\n",
    "    predicted_classes = torch.argmax(predictions, dim=1)\n",
    "    # Convert to numpy for sklearn metrics\n",
    "    y_pred = predicted_classes.numpy()\n",
    "    y_true = y_test_tensor_manSelF_bal.numpy()\n",
    "    # Calculate accuracy\n",
    "    acc_manSelF_bal = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy (selected features): {acc_manSelF_bal:.4f}\")\n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "epsilon = privacy_engine.get_epsilon(delta=1e-5)\n",
    "print(f\"Final ε: {epsilon:.2f}\")\n",
    "\n",
    "save_file(model_manSelF_bal, os.path.join(models_dir, 'deepL_manSelF_bal_dp_model.pkl'))\n",
    "# Save model performance\n",
    "classification_report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "save_model_performance(classification_report_dict, 'deepL_manSelF_bal_dp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# File paths for all models\n",
    "model_files = [\n",
    "    'models/deepL_allF_bal_model.pkl',\n",
    "    'models/deepL_selF_bal_model.pkl',\n",
    "    'models/deepL_manSelF_bal_model.pkl',\n",
    "    'models/deepL_allF_bal_dp_model.pkl',\n",
    "    'models/deepL_selF_bal_dp_model.pkl',\n",
    "    'models/deepL_manSelF_bal_dp_model.pkl',\n",
    "]\n",
    "\n",
    "# Load all models\n",
    "with open(model_files[0], 'rb') as file:\n",
    "    deepL_model_allF = pickle.load(file)\n",
    "with open(model_files[1], 'rb') as file:\n",
    "    deepL_model_selF = pickle.load(file)\n",
    "with open(model_files[2], 'rb') as file:\n",
    "    deepL_model_manSelF = pickle.load(file)\n",
    "with open(model_files[3], 'rb') as file:\n",
    "    deepL_model_allF_dp = pickle.load(file)\n",
    "with open(model_files[4], 'rb') as file:\n",
    "    deepL_model_selF_dp = pickle.load(file)\n",
    "with open(model_files[5], 'rb') as file:\n",
    "    deepL_model_manSelF_dp = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Model Inversion Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get models\n",
    "deepL_model_allF_copy = copy.deepcopy(deepL_model_allF)\n",
    "deepL_model_manSelF_copy = copy.deepcopy(deepL_model_manSelF)\n",
    "deepL_model_selF_copy = copy.deepcopy(deepL_model_selF)\n",
    "deepL_model_allF_dp_copy = copy.deepcopy(deepL_model_allF_dp)\n",
    "deepL_model_selF_dp_copy = copy.deepcopy(deepL_model_selF_dp)\n",
    "deepL_model_manSelF_dp_copy = copy.deepcopy(deepL_model_manSelF_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inversion_attack_nn(model, target_class, feature_names, X_train, scaler=None, iterations=300):\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Get min/max values for each feature\n",
    "    min_values = X_train[feature_names].min()\n",
    "    max_values = X_train[feature_names].max()\n",
    "    \n",
    "    # Start with random values for the features\n",
    "    sample = {}\n",
    "    for feature in feature_names:\n",
    "        sample[feature] = np.random.uniform(min_values[feature], max_values[feature])\n",
    "    \n",
    "    # Save best sample and confidence\n",
    "    best_sample = sample.copy()\n",
    "    best_confidence = 0\n",
    "    \n",
    "    # Optimize sample through iterations\n",
    "    step_size = 0.05\n",
    "    for i in range(iterations):\n",
    "        # Create DataFrame and convert to tensor\n",
    "        current_df = pd.DataFrame([sample])\n",
    "        \n",
    "        # Scale the data if a scaler is provided\n",
    "        if scaler:\n",
    "            current_data = scaler.transform(current_df)\n",
    "        else:\n",
    "            current_data = current_df.values\n",
    "        \n",
    "        # Convert to PyTorch tensor\n",
    "        current_tensor = torch.tensor(current_data, dtype=torch.float32)\n",
    "        \n",
    "        # Get prediction\n",
    "        with torch.no_grad():\n",
    "            output = model(current_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "            confidence = probabilities[0][target_class].item()\n",
    "        \n",
    "        # Save if better than previous\n",
    "        if confidence > best_confidence:\n",
    "            best_confidence = confidence\n",
    "            best_sample = sample.copy()\n",
    "        \n",
    "        # Optimize one feature at a time\n",
    "        for feature in feature_names:\n",
    "            original = sample[feature]\n",
    "            \n",
    "            # Try positive change\n",
    "            sample[feature] = min(max_values[feature], original + step_size)\n",
    "            \n",
    "            # Create and scale data\n",
    "            plus_df = pd.DataFrame([sample])\n",
    "            if scaler:\n",
    "                plus_data = scaler.transform(plus_df)\n",
    "            else:\n",
    "                plus_data = plus_df.values\n",
    "                \n",
    "            # Get prediction\n",
    "            plus_tensor = torch.tensor(plus_data, dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                plus_output = model(plus_tensor)\n",
    "                plus_probs = torch.nn.functional.softmax(plus_output, dim=1)\n",
    "                plus_conf = plus_probs[0][target_class].item()\n",
    "            \n",
    "            # Try negative change\n",
    "            sample[feature] = max(min_values[feature], original - step_size)\n",
    "            \n",
    "            # Create and scale data\n",
    "            minus_df = pd.DataFrame([sample])\n",
    "            if scaler:\n",
    "                minus_data = scaler.transform(minus_df)\n",
    "            else:\n",
    "                minus_data = minus_df.values\n",
    "                \n",
    "            # Get prediction\n",
    "            minus_tensor = torch.tensor(minus_data, dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                minus_output = model(minus_tensor)\n",
    "                minus_probs = torch.nn.functional.softmax(minus_output, dim=1)\n",
    "                minus_conf = minus_probs[0][target_class].item()\n",
    "            \n",
    "            # Choose the best direction\n",
    "            if plus_conf > minus_conf and plus_conf > confidence:\n",
    "                sample[feature] = min(max_values[feature], original + step_size)\n",
    "            elif minus_conf > plus_conf and minus_conf > confidence:\n",
    "                sample[feature] = max(min_values[feature], original - step_size)\n",
    "            else:\n",
    "                sample[feature] = original\n",
    "        \n",
    "        # Reduce step size over time\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            step_size *= 0.9\n",
    "    \n",
    "    # Find most similar training example\n",
    "    reconstructed_df = pd.DataFrame([best_sample])\n",
    "    \n",
    "    # Calculate distance to each training example\n",
    "    distances = []\n",
    "    for _, row in X_train.iterrows():\n",
    "        dist = 0\n",
    "        for feature in feature_names:\n",
    "            dist += (row[feature] - best_sample[feature])**2\n",
    "        distances.append(np.sqrt(dist))\n",
    "    \n",
    "    most_similar_idx = np.argmin(distances)\n",
    "    most_similar = X_train.iloc[[most_similar_idx]]\n",
    "    \n",
    "    return {\n",
    "        'reconstructed': reconstructed_df,\n",
    "        'most_similar': most_similar,\n",
    "        'confidence': best_confidence,\n",
    "        'similarity': 1.0 / (1.0 + np.min(distances))  # Convert distance to similarity (0-1)\n",
    "    }\n",
    "\n",
    "def analyze_model_inversion_attack(attack_results, feature_names):\n",
    "    print(f\"Attack completed with confidence: {attack_results['confidence']:.4f}\")\n",
    "    print(f\"Similarity to closest training sample: {attack_results['similarity']:.4f}\")\n",
    "    \n",
    "    # Visualize comparison between reconstructed and original sample\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Get data for visualization\n",
    "    recon = attack_results['reconstructed']\n",
    "    orig = attack_results['most_similar']\n",
    "    \n",
    "    # Plot all features\n",
    "    display_features = feature_names\n",
    "    \n",
    "    x = np.arange(len(display_features))\n",
    "    width = 0.3\n",
    "    \n",
    "    plt.bar(x - width/2, [recon[f].values[0] for f in display_features], width, label='Reconstructed')\n",
    "    plt.bar(x + width/2, [orig[f].values[0] for f in display_features], width, label='Original')\n",
    "    \n",
    "    plt.xlabel('Features')\n",
    "    plt.ylabel('Values')\n",
    "    plt.title('Model Inversion Attack: Reconstructed vs. Original Sample')\n",
    "    plt.xticks(x, display_features, rotation=45)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Compare all features in detail\n",
    "    print(\"\\n FEATURE-SPECIFIC ANALYSIS\")\n",
    "    for feature in feature_names:\n",
    "        recon_value = recon[feature].values[0]\n",
    "        orig_value = orig[feature].values[0]\n",
    "        \n",
    "        diff = abs(recon_value - orig_value)\n",
    "        \n",
    "        print(f\"Feature: {feature}\")\n",
    "        print(f\"  Original value: {orig_value:.2f}\")\n",
    "        print(f\"  Reconstructed value: {recon_value:.2f}\")\n",
    "        print(f\"  Absolute difference: {diff:.2f}\")\n",
    "        print()\n",
    "    \n",
    "    return attack_results\n",
    "\n",
    "def run_attack_on_model(model, target_class, feature_names, X_train, scaler=None):\n",
    "    # Run model inversion attack on a specific model\n",
    "    results = model_inversion_attack_nn(\n",
    "        model=model,\n",
    "        target_class=target_class,\n",
    "        feature_names=feature_names,\n",
    "        X_train=X_train,\n",
    "        scaler=scaler\n",
    "    )\n",
    "    \n",
    "    analyze_model_inversion_attack(results, feature_names)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scaler_for_model(X_data):\n",
    "    # Create and fit a StandardScaler for the data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_data)\n",
    "    return scaler\n",
    "\n",
    "# Create scalers for each model\n",
    "scaler_all = create_scaler_for_model(X_train_bal)\n",
    "scaler_manSelF = create_scaler_for_model(X_train_bal[manual_important_features])\n",
    "scaler_selF = create_scaler_for_model(X_train_bal[important_features])\n",
    "\n",
    "# Run attack on All Features Model\n",
    "print(\"\\nMODEL INVERSION ATTACK: ALL FEATURES\")\n",
    "results_all = model_inversion_attack_nn(\n",
    "    model=deepL_model_allF_copy, \n",
    "    target_class=1, \n",
    "    feature_names=X_train_bal.columns.tolist(), \n",
    "    X_train=X_train_bal,\n",
    "    scaler=scaler_all\n",
    ")\n",
    "analyze_model_inversion_attack(results_all, X_train_bal.columns.tolist())\n",
    "\n",
    "# Run attack on Manual Selected Features Model\n",
    "print(\"\\nMODEL INVERSION ATTACK: MANUAL SELECTED FEATURES\")\n",
    "results_manSelF = model_inversion_attack_nn(\n",
    "    model=deepL_model_manSelF_copy, \n",
    "    target_class=1, \n",
    "    feature_names=manual_important_features, \n",
    "    X_train=X_train_bal[manual_important_features],\n",
    "    scaler=scaler_manSelF\n",
    ")\n",
    "analyze_model_inversion_attack(results_manSelF, manual_important_features)\n",
    "\n",
    "# Run attack on Selected Features Model\n",
    "print(\"\\nMODEL INVERSION ATTACK: SELECTED FEATURES\")\n",
    "results_selF = model_inversion_attack_nn(\n",
    "    model=deepL_model_selF_copy, \n",
    "    target_class=1, \n",
    "    feature_names=important_features, \n",
    "    X_train=X_train_bal[important_features],\n",
    "    scaler=scaler_selF\n",
    ")\n",
    "analyze_model_inversion_attack(results_selF, important_features)\n",
    "\n",
    "# Compare all models\n",
    "print(\"\\nATTACK EFFECTIVENESS COMPARISON\")\n",
    "print(f\"{'Model':<25} {'Confidence':<15} {'Similarity':<15}\")\n",
    "print(f\"{'-'*25:<25} {'-'*15:<15} {'-'*15:<15}\")\n",
    "print(f\"{'All Features':<25} {results_all['confidence']:<15.4f} {results_all['similarity']:<15.4f}\")\n",
    "print(f\"{'Manual Selected Features':<25} {results_manSelF['confidence']:<15.4f} {results_manSelF['similarity']:<15.4f}\")\n",
    "print(f\"{'Selected Features':<25} {results_selF['confidence']:<15.4f} {results_selF['similarity']:<15.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Membership Inference Attack(MIA) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---1. Standard MIA---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this attack is to determine whether a given sample was used in training. \n",
    "\n",
    "It queries the model with different data points and analyzes the confidence scores. This happens because the model behaves differently for data it has seen before and new data. As this one was trained without DP, it is easier to leak private data as it may have \"memorized\" training data. A classification model would classify a training data record to its true class with a high confidence score while classifying a test data record to its true class with a relatively small confidence. These different behaviors of ML models enable an attacker of MIAs to build attack models to distinguish members from non-members of the training dataset.\n",
    "\n",
    "The more overfitted a machine learning model is, the easier it will be for an adversary to stage membership inference attacks against it. Therefore, a machine model that generalizes well on unseen examples is also more secure against membership inference.\n",
    "\n",
    "Membership inference attacks are not successful on all kinds of machine learning tasks. To create an efficient attack model, the adversary must be able to explore the feature space. (HigRes. photos: Hard, tabular data: Easy)\n",
    "\n",
    "** TODO: try with DP model(s) as well **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get models\n",
    "deepL_model_allF_copy = copy.deepcopy(deepL_model_allF)\n",
    "deepL_model_manSelF_copy = copy.deepcopy(deepL_model_manSelF)\n",
    "deepL_model_selF_copy = copy.deepcopy(deepL_model_selF)\n",
    "deepL_model_allF_dp_copy = copy.deepcopy(deepL_model_allF_dp)\n",
    "deepL_model_selF_dp_copy = copy.deepcopy(deepL_model_selF_dp)\n",
    "deepL_model_manSelF_dp_copy = copy.deepcopy(deepL_model_manSelF_dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_threshold(X_train, model, feature_names, scaler=None):\n",
    "    \"\"\"\n",
    "    Calculate a dynamic threshold based on the maximum observed confidence \n",
    "    for samples in the training set.\n",
    "    \"\"\"\n",
    "    max_confidence = 0\n",
    "    for i in range(len(X_train)):\n",
    "        sample = X_train.iloc[i][feature_names]\n",
    "        df_sample = pd.DataFrame([sample])\n",
    "        sample_data = scaler.transform(df_sample) if scaler else df_sample.values\n",
    "        sample_tensor = torch.tensor(sample_data, dtype=torch.float32)\n",
    "\n",
    "        # Get model prediction and confidence\n",
    "        with torch.no_grad():\n",
    "            output = model(sample_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "            confidence = probabilities[0].max().item()  # max confidence across all classes\n",
    "\n",
    "        if confidence > max_confidence:\n",
    "            max_confidence = confidence\n",
    "\n",
    "    # Define a dynamic threshold based on a fraction of the maximum confidence\n",
    "    return max_confidence * 0.8  # For example, 80% of the maximum confidence observed\n",
    "\n",
    "def membership_inference_attack_nn(model, target_class, feature_names, X_train, scaler=None, iterations=300):\n",
    "    model.eval()\n",
    "\n",
    "    # Get min/max values for each feature\n",
    "    min_values = X_train[feature_names].min()\n",
    "    max_values = X_train[feature_names].max()\n",
    "\n",
    "    # Initialize random sample\n",
    "    sample = {feature: np.random.uniform(min_values[feature], max_values[feature]) for feature in feature_names}\n",
    "\n",
    "    best_sample = sample.copy()\n",
    "    best_confidence = 0\n",
    "    confidence_history = []  # To track confidence over iterations\n",
    "    step_size = 0.05\n",
    "\n",
    "    # Calculate dynamic threshold\n",
    "    dynamic_thresh = dynamic_threshold(X_train, model, feature_names, scaler)\n",
    "    print(f\"Dynamic Threshold: {dynamic_thresh:.4f}\")\n",
    "\n",
    "    # Optimize sample over iterations\n",
    "    for i in range(iterations):\n",
    "        current_df = pd.DataFrame([sample])\n",
    "        current_data = scaler.transform(current_df) if scaler else current_df.values\n",
    "        current_tensor = torch.tensor(current_data, dtype=torch.float32)\n",
    "\n",
    "        # Get model prediction and confidence\n",
    "        with torch.no_grad():\n",
    "            output = model(current_tensor)\n",
    "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "            confidence = probabilities[0][target_class].item()\n",
    "\n",
    "        confidence_history.append(confidence)\n",
    "\n",
    "        # Save best sample and confidence\n",
    "        if confidence > best_confidence:\n",
    "            best_confidence = confidence\n",
    "            best_sample = sample.copy()\n",
    "\n",
    "        # Optimize sample by adjusting one feature at a time\n",
    "        for feature in feature_names:\n",
    "            original = sample[feature]\n",
    "\n",
    "            # Try positive change\n",
    "            sample[feature] = min(max_values[feature], original + step_size)\n",
    "            plus_df = pd.DataFrame([sample])\n",
    "            plus_data = scaler.transform(plus_df) if scaler else plus_df.values\n",
    "            plus_tensor = torch.tensor(plus_data, dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                plus_output = model(plus_tensor)\n",
    "                plus_conf = torch.nn.functional.softmax(plus_output, dim=1)[0][target_class].item()\n",
    "\n",
    "            # Try negative change\n",
    "            sample[feature] = max(min_values[feature], original - step_size)\n",
    "            minus_df = pd.DataFrame([sample])\n",
    "            minus_data = scaler.transform(minus_df) if scaler else minus_df.values\n",
    "            minus_tensor = torch.tensor(minus_data, dtype=torch.float32)\n",
    "            with torch.no_grad():\n",
    "                minus_output = model(minus_tensor)\n",
    "                minus_conf = torch.nn.functional.softmax(minus_output, dim=1)[0][target_class].item()\n",
    "\n",
    "            # Choose the best direction\n",
    "            if plus_conf > minus_conf and plus_conf > confidence:\n",
    "                sample[feature] = min(max_values[feature], original + step_size)\n",
    "            elif minus_conf > plus_conf and minus_conf > confidence:\n",
    "                sample[feature] = max(min_values[feature], original - step_size)\n",
    "            else:\n",
    "                sample[feature] = original\n",
    "\n",
    "        # Reduce step size over time for finer tuning\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            step_size *= 0.9\n",
    "\n",
    "    # Determine membership using dynamic threshold\n",
    "    is_member = best_confidence > dynamic_thresh\n",
    "\n",
    "    # Find the most similar training example\n",
    "    reconstructed_df = pd.DataFrame([best_sample])\n",
    "\n",
    "    # Fix here: Convert best_sample to NumPy array for comparison\n",
    "    best_sample_values = np.array([best_sample[feature] for feature in feature_names])  # Convert to NumPy array\n",
    "    distances = [np.linalg.norm(X_train[feature_names].iloc[idx].values - best_sample_values) for idx in range(X_train.shape[0])]\n",
    "\n",
    "    most_similar_idx = np.argmin(distances)\n",
    "    most_similar = X_train.iloc[[most_similar_idx]]\n",
    "\n",
    "    return {\n",
    "        'reconstructed': reconstructed_df,\n",
    "        'most_similar': most_similar,\n",
    "        'confidence': best_confidence,\n",
    "        'membership': is_member,\n",
    "        'similarity': 1.0 / (1.0 + np.min(distances)),\n",
    "        'confidence_history': confidence_history  # Track confidence evolution\n",
    "    }\n",
    "\n",
    "def analyze_membership_inference_attack(attack_results, feature_names):\n",
    "    print(f\"Attack completed with confidence: {attack_results['confidence']:.4f}\")\n",
    "    print(f\"Membership prediction: {'Member' if attack_results['membership'] else 'Not Member'}\")\n",
    "    print(f\"Similarity to closest training sample: {attack_results['similarity']:.4f}\")\n",
    "    \n",
    "    # Plot evolution of confidence over iterations\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(len(attack_results['confidence_history'])), attack_results['confidence_history'], label='Confidence Evolution')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Confidence')\n",
    "    plt.title('Confidence Evolution Over Attack Iterations')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def run_attack_on_model(model, target_class, feature_names, X_train, scaler=None):\n",
    "    # Run membership inference attack on a specific model\n",
    "    results = membership_inference_attack_nn(\n",
    "        model=model,\n",
    "        target_class=target_class,\n",
    "        feature_names=feature_names,\n",
    "        X_train=X_train,\n",
    "        scaler=scaler\n",
    "    )\n",
    "    \n",
    "    analyze_membership_inference_attack(results, feature_names)\n",
    "    return results\n",
    "\n",
    "def create_scaler_for_model(X_data):\n",
    "    # Create and fit a StandardScaler for the data\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_data)\n",
    "    return scaler\n",
    "\n",
    "# Example usage\n",
    "scaler_all = create_scaler_for_model(X_train_bal)\n",
    "scaler_manSelF = create_scaler_for_model(X_train_bal[manual_important_features])\n",
    "scaler_selF = create_scaler_for_model(X_train_bal[important_features])\n",
    "\n",
    "# Run attack on All Features Model\n",
    "print(\"\\nMEMBERSHIP INFERENCE ATTACK\")\n",
    "print(\"allF:\")\n",
    "results_all = run_attack_on_model(\n",
    "    model=deepL_model_allF_copy, \n",
    "    target_class=1, \n",
    "    feature_names=X_train_bal.columns.tolist(), \n",
    "    X_train=X_train_bal,\n",
    "    scaler=scaler_all\n",
    ")\n",
    "print(\"allF_dp:\")\n",
    "results_all_dp = run_attack_on_model(\n",
    "    model=deepL_model_allF_dp_copy, \n",
    "    target_class=1, \n",
    "    feature_names=X_train_bal.columns.tolist(), \n",
    "    X_train=X_train_bal,\n",
    "    scaler=scaler_all\n",
    ")\n",
    "\n",
    "# Run attack on Manual Selected Features Model\n",
    "print(\"\\nMEMBERSHIP INFERENCE ATTACK\")\n",
    "print(\"manSelF:\")\n",
    "results_manSelF = run_attack_on_model(\n",
    "    model=deepL_model_manSelF_copy, \n",
    "    target_class=1, \n",
    "    feature_names=manual_important_features, \n",
    "    X_train=X_train_bal[manual_important_features],\n",
    "    scaler=scaler_manSelF\n",
    ")\n",
    "print(\"manSelF_dp:\")\n",
    "results_manSelF_dp = run_attack_on_model(\n",
    "    model=deepL_model_manSelF_dp_copy,\n",
    "    target_class=1,\n",
    "    feature_names=manual_important_features,\n",
    "    X_train=X_train_bal[manual_important_features],\n",
    "    scaler=scaler_manSelF\n",
    ")\n",
    "\n",
    "# Run attack on Selected Features Model\n",
    "print(\"\\nMEMBERSHIP INFERENCE ATTACK\")\n",
    "print(\"selF:\")\n",
    "results_selF = run_attack_on_model(\n",
    "    model=deepL_model_selF_copy, \n",
    "    target_class=1, \n",
    "    feature_names=important_features, \n",
    "    X_train=X_train_bal[important_features],\n",
    "    scaler=scaler_selF\n",
    ")\n",
    "print(\"selF_dp:\")\n",
    "results_selF_dp = run_attack_on_model(\n",
    "    model=deepL_model_selF_dp_copy, \n",
    "    target_class=1, \n",
    "    feature_names=important_features, \n",
    "    X_train=X_train_bal[important_features],\n",
    "    scaler=scaler_selF\n",
    ")\n",
    "\n",
    "# Compare all models\n",
    "print(\"\\nATTACK EFFECTIVENESS COMPARISON\")\n",
    "print(f\"{'Model':<25} {'Confidence':<15} {'Similarity':<15}\")\n",
    "print(f\"{'-'*25:<25} {'-'*15:<15} {'-'*15:<15}\")\n",
    "print(\"\\nWithout DP:\")\n",
    "print(f\"{'All Features':<25} {results_all['confidence']:<15.4f} {results_all['similarity']:<15.4f}\")\n",
    "print(f\"{'Manual Selected Features':<25} {results_manSelF['confidence']:<15.4f} {results_manSelF['similarity']:<15.4f}\")\n",
    "print(f\"{'Selected Features':<25} {results_selF['confidence']:<15.4f} {results_selF['similarity']:<15.4f}\")\n",
    "print(\"\\nWith DP:\")\n",
    "print(f\"{'All Features':<25} {results_all_dp['confidence']:<15.4f} {results_all_dp['similarity']:<15.4f}\")\n",
    "print(f\"{'Manual Selected Features':<25} {results_manSelF_dp['confidence']:<15.4f} {results_manSelF_dp['similarity']:<15.4f}\")\n",
    "print(f\"{'Selected Features':<25} {results_selF_dp['confidence']:<15.4f} {results_selF_dp['similarity']:<15.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As features are reduced, attack confidence drops, but similarity increases. This means that fewer, well-chosen features let the attack reconstruct samples closer to reality, even if less sure. The selected features expose more structure for the attacker.\n",
    "\n",
    "TODO: maybe add the data of each reconstructed member in the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- 2. Real World Case MIA ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To keep: For development\n",
    "# real_members = X_train.head(5)\n",
    "# print(\"First 5 Real Members (Training Set):\\n\", real_members)\n",
    "\n",
    "risky_patients = [\n",
    "    # If adding more patients, make sure that the attributes have valid values according to the dataset\n",
    "\n",
    "    {\n",
    "        'GenHlth': 3, 'HighBP': 1, 'DiffWalk': 0, 'BMI': 21, 'HighChol': 0, 'Age': 12, \n",
    "        'HeartDiseaseorAttack': 0, 'PhysHlth': 0, 'Stroke': 0, 'MentHlth': 0, 'CholCheck': 1, \n",
    "        'Smoker': 0, 'Veggies': 1, 'HvyAlcoholConsump': 0, 'PhysActivity': 1, 'Education': 4, \n",
    "        'Income': 4\n",
    "    },  # Patient used in the test_set. ID nr 178592\n",
    "\n",
    "    {\n",
    "        'GenHlth': 2, 'HighBP': 1, 'DiffWalk': 0, 'BMI': 39, 'HighChol': 1, 'Age': 7, \n",
    "        'HeartDiseaseorAttack': 0, 'PhysHlth': 0, 'Stroke': 0, 'MentHlth': 0, 'CholCheck': 1, \n",
    "        'Smoker': 0, 'Veggies': 1, 'HvyAlcoholConsump': 0, 'PhysActivity': 1, 'Education': 4, \n",
    "        'Income': 1\n",
    "    },  # Patient used in the test_set. ID nr 318886\n",
    "\n",
    "    {\n",
    "        'GenHlth': 4, 'HighBP': 0, 'DiffWalk': 1, 'BMI': 23, 'HighChol': 0, 'Age': 8, \n",
    "        'HeartDiseaseorAttack': 1, 'PhysHlth': 24, 'Stroke': 0, 'MentHlth': 22, 'CholCheck': 0, \n",
    "        'Smoker': 1, 'Veggies': 0, 'HvyAlcoholConsump': 1, 'PhysActivity': 0, 'Education': 2, \n",
    "        'Income': 1\n",
    "    },  # Random person created for testing purposes\n",
    "\n",
    "    {\n",
    "        'GenHlth': 5, 'HighBP': 1, 'DiffWalk': 1, 'BMI': 40, 'HighChol': 1, 'Age': 9, \n",
    "        'HeartDiseaseorAttack': 0, 'PhysHlth': 15, 'Stroke': 0, 'MentHlth': 18, 'CholCheck': 1, \n",
    "        'Smoker': 1, 'Veggies': 1, 'HvyAlcoholConsump': 0, 'PhysActivity': 0, 'Education': 4, \n",
    "        'Income': 3\n",
    "    }   # Patient ID 0. Taken from the dataset. Probably not used in test_set? - ToDo\n",
    "]\n",
    "\n",
    "# Convert risky patients to pandas dataFrame as it is the expected input format by the deepL model\n",
    "risky_df = pd.DataFrame(risky_patients)\n",
    "\n",
    "risky_df = risky_df[X_train.columns]\n",
    "\n",
    "# Predict confidence scores for risky patients\n",
    "risky_confidences = rf_model.predict_proba(risky_df).max(axis=1)\n",
    "\n",
    "# Determine membership status using the same attack threshold from the standard MIAttack\n",
    "risky_membership = ['Member' if c > threshold else 'Non-Member' for c in risky_confidences]\n",
    "\n",
    "for i, (conf, membership) in enumerate(zip(risky_confidences, risky_membership)):\n",
    "    print(f\"Risky Patient {i + 1}: Confidence = {conf:.2f}, Predicted Membership = {membership}\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(train_confidences, bins=50, alpha=0.6, color='blue', label=\"Train (Member)\")\n",
    "plt.hist(test_confidences, bins=50, alpha=0.6, color='red', label=\"Test (Non-Member)\")\n",
    "\n",
    "for i, conf in enumerate(risky_confidences):\n",
    "    plt.axvline(conf, color='green', linestyle='dashed', label=f\"Risky Patient {i + 1}: {conf:.2f}\")\n",
    "\n",
    "plt.axvline(threshold, color='black', linestyle='solid', label=f\"Attack Threshold: {threshold:.2f}\")\n",
    "plt.xlabel(\"Model Confidence Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Membership Inference Attack - Risky Patients\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add description, explain results and describe and how it can relate to a real world case (like an insurance company)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #### 6.3 Attribute Inference Attack -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get models\n",
    "# deepL_model_allF_copy = copy.deepcopy(deepL_model_allF)\n",
    "# deepL_model_manSelF_copy = copy.deepcopy(deepL_model_manSelF)\n",
    "# deepL_model_selF_copy = copy.deepcopy(deepL_model_selF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tabulate import tabulate\n",
    "\n",
    "# assert 'rf_model' in locals(), \"Deep Learning model (rf_model) is not defined!\" #if not defined, run 6.6\n",
    "\n",
    "# sensitive_feature = 'Income'\n",
    "\n",
    "# # Exclude 'Income' from training features - because we will be trying to infer this attribute\n",
    "# attack_features = [f for f in X_train.columns if f != sensitive_feature]\n",
    "\n",
    "# # Get confidence scores from the target model\n",
    "# # For each prediction, predict_proba() gives an array of probabilities for each class (8 in case of Income)\n",
    "# train_confidences = rf_model.predict_proba(X_train).max(axis=1)\n",
    "# test_confidences = rf_model.predict_proba(X_test).max(axis=1)\n",
    "\n",
    "# # Add confidence scores to the dataset\n",
    "# X_train_attack = X_train[attack_features].copy()\n",
    "# X_train_attack['model_confidence'] = train_confidences\n",
    "\n",
    "# X_test_attack = X_test[attack_features].copy()\n",
    "# X_test_attack['model_confidence'] = test_confidences\n",
    "\n",
    "\n",
    "# y_train_attack = X_train[sensitive_feature]\n",
    "# y_test_attack = X_test[sensitive_feature]\n",
    "\n",
    "# # Train the Inference Model (using deep learning)\n",
    "# rf_model.fit(X_train_attack, y_train_attack)\n",
    "\n",
    "# # Evaluate the Inference Model\n",
    "# y_pred_attack = rf_model.predict(X_test_attack)\n",
    "\n",
    "# attack_accuracy = accuracy_score(y_test_attack, y_pred_attack)\n",
    "\n",
    "# train_mean_conf = np.mean(train_confidences)\n",
    "# test_mean_conf = np.mean(test_confidences)\n",
    "\n",
    "# print(\"\\nAttribute Inference Attack on 'Income':\")\n",
    "# print(f\"Attack Accuracy: {attack_accuracy:.2f}\")\n",
    "# print(f\"Avg Train Confidence: {train_mean_conf:.2f}\")\n",
    "# print(f\"Avg Test Confidence: {test_mean_conf:.2f}\\n\")\n",
    "\n",
    "# report = classification_report(y_test_attack, y_pred_attack, output_dict=True)\n",
    "\n",
    "# def print_classification_report(report):\n",
    "#     headers = [\"Metric\"] + [str(label) for label in report if label not in ('accuracy', 'macro avg', 'weighted avg')]\n",
    "#     rows = [\n",
    "#         [\"Precision\"] + [report[label]['precision'] for label in report if label not in ('accuracy', 'macro avg', 'weighted avg')],\n",
    "#         [\"Recall\"] + [report[label]['recall'] for label in report if label not in ('accuracy', 'macro avg', 'weighted avg')],\n",
    "#         [\"F1-Score\"] + [report[label]['f1-score'] for label in report if label not in ('accuracy', 'macro avg', 'weighted avg')],\n",
    "#         [\"Support\"] + [report[label]['support'] for label in report if label not in ('accuracy', 'macro avg', 'weighted avg')]\n",
    "#     ]\n",
    "\n",
    "#     # Add macro and weighted averages\n",
    "#     rows.append([\"Macro Avg\", report['macro avg']['precision'], report['macro avg']['recall'], report['macro avg']['f1-score'], report['macro avg']['support']])\n",
    "#     rows.append([\"Weighted Avg\", report['weighted avg']['precision'], report['weighted avg']['recall'], report['weighted avg']['f1-score'], report['weighted avg']['support']])\n",
    "#     rows.append([\"Accuracy\", \"\", \"\", report['accuracy'], \"\"])\n",
    "\n",
    "#     print(tabulate(rows, headers=headers, tablefmt=\"grid\", floatfmt=\".2f\"))\n",
    "\n",
    "# plt.figure(figsize=(10, 7))\n",
    "# plt.hist(train_confidences, bins=50, alpha=0.6, label=\"Train (Member)\", color='blue')\n",
    "# plt.hist(test_confidences, bins=50, alpha=0.6, label=\"Test (Non-Member)\", color='red')\n",
    "# plt.axvline(train_mean_conf, color='blue', linestyle='dashed', linewidth=1, label=f\"Mean Train Confidence: {train_mean_conf:.2f}\")\n",
    "# plt.axvline(test_mean_conf, color='red', linestyle='dashed', linewidth=1, label=f\"Mean Test Confidence: {test_mean_conf:.2f}\")\n",
    "# plt.xlabel(\"Model Confidence Score\")\n",
    "# plt.ylabel(\"Count\")\n",
    "# plt.legend()\n",
    "# plt.title(\"Attribute Inference Attack - Confidence Distribution\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attack achieved 47% accuracy, meaning it correctly inferred the income level of individuals nearly half the time. As the Income attribute has 8 levels, it is normal that the accuracy is lower. If the attack tried to guess randomly, it would be around 12,5% (1/8 *100). Therefore data is leaking. \n",
    "\n",
    "Also, the model showed higher confidence on training data (0.91) than test data (0.83), indicating a potential privacy risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #### 6.4 Find most exposed individuals and the analyzing the infered data -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add predictions and confidence to the test dataset for analysis\n",
    "# vulnerable_data = X_test_attack.copy()\n",
    "# vulnerable_data['True_Income'] = y_test_attack.values\n",
    "# vulnerable_data['Predicted_Income'] = y_pred_attack\n",
    "\n",
    "# # Calculate prediction correctness\n",
    "# vulnerable_data['Correct_Prediction'] = (vulnerable_data['True_Income'] == vulnerable_data['Predicted_Income'])\n",
    "\n",
    "# # Fidn top 20 most vulnerable individuals (highest confidence)\n",
    "# most_vulnerable = vulnerable_data.sort_values(by='model_confidence', ascending=False).head(20)\n",
    "\n",
    "# print(\"Most Vulnerable Individuals (Top 20 by Confidence Score):\")\n",
    "# print(tabulate(most_vulnerable[['model_confidence', 'True_Income', 'Predicted_Income', 'Correct_Prediction']],\n",
    "#                headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 20 most vulnerable individuals had a model confidence of 1.0, meaning the model was completely certain about their predicted income. 16 out of 20 predictions were completely correct (80%), highlighting a significant privacy concern for these individuals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 . Evaluation & Performance Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 . Results & Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 . Conclusion & Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
